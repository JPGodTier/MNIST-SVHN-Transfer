nohup: ignoring input
Using downloaded and verified file: ./data/SVHN/raw/train_32x32.mat
Using downloaded and verified file: ./data/SVHN/raw/test_32x32.mat
Using device cuda
Training starts
Epoch [1/10] starts
Iteration 50: Loss_G: 10.1814, Loss_D: 0.0388
Iteration 100: Loss_G: 5.7776, Loss_D: 0.0220
Iteration 150: Loss_G: 4.2706, Loss_D: 0.0361
Iteration 200: Loss_G: 3.9187, Loss_D: 0.0464
Iteration 250: Loss_G: 3.8443, Loss_D: 0.0734
Iteration 300: Loss_G: 3.9599, Loss_D: 0.0450
Iteration 350: Loss_G: 3.8065, Loss_D: 0.0466
Iteration 400: Loss_G: 3.6029, Loss_D: 0.0220
Iteration 450: Loss_G: 3.6658, Loss_D: 0.0497
Iteration 500: Loss_G: 3.7947, Loss_D: 0.0416
Iteration 550: Loss_G: 3.5445, Loss_D: 0.0422
Iteration 600: Loss_G: 3.7544, Loss_D: 0.0284
Iteration 650: Loss_G: 3.6546, Loss_D: 0.0155
Iteration 700: Loss_G: 3.4647, Loss_D: 0.0155
Iteration 750: Loss_G: 3.4642, Loss_D: 0.0241
Iteration 800: Loss_G: 3.5947, Loss_D: 0.0233
Iteration 850: Loss_G: 3.5678, Loss_D: 0.0194
Iteration 900: Loss_G: 3.6114, Loss_D: 0.0328
Iteration 950: Loss_G: 3.4290, Loss_D: 0.0295
Iteration 1000: Loss_G: 3.5296, Loss_D: 0.0324
Iteration 1050: Loss_G: 3.4889, Loss_D: 0.0038
Iteration 1100: Loss_G: 3.3447, Loss_D: 0.0158
Iteration 1150: Loss_G: 3.4337, Loss_D: 0.0258
Iteration 1200: Loss_G: 3.4050, Loss_D: 0.0295
Epoch [1/10], Loss_G: 3.2780, Loss_D: 0.0316
Epoch [2/10] starts
Iteration 50: Loss_G: 3.3505, Loss_D: 0.0232
Iteration 100: Loss_G: 3.2894, Loss_D: 0.0313
Iteration 150: Loss_G: 3.5030, Loss_D: 0.0250
Iteration 200: Loss_G: 3.4398, Loss_D: 0.0049
Iteration 250: Loss_G: 3.4133, Loss_D: 0.0158
Iteration 300: Loss_G: 3.4780, Loss_D: 0.0231
Iteration 350: Loss_G: 3.3487, Loss_D: 0.0178
Iteration 400: Loss_G: 3.3426, Loss_D: 0.0251
Iteration 450: Loss_G: 3.4255, Loss_D: 0.0207
Iteration 500: Loss_G: 3.3458, Loss_D: 0.0296
Iteration 550: Loss_G: 3.3644, Loss_D: 0.0377
Iteration 600: Loss_G: 3.4869, Loss_D: 0.0146
Iteration 650: Loss_G: 3.4074, Loss_D: 0.0104
Iteration 700: Loss_G: 3.3966, Loss_D: 0.0233
Iteration 750: Loss_G: 3.3925, Loss_D: 0.0269
Iteration 800: Loss_G: 3.2422, Loss_D: 0.0304
Iteration 850: Loss_G: 3.2172, Loss_D: 0.0380
Iteration 900: Loss_G: 3.4338, Loss_D: 0.0417
Iteration 950: Loss_G: 3.3779, Loss_D: 0.0409
Iteration 1000: Loss_G: 3.4649, Loss_D: 0.0537
Iteration 1050: Loss_G: 3.4552, Loss_D: 0.0416
Iteration 1100: Loss_G: 3.3050, Loss_D: 0.0584
Iteration 1150: Loss_G: 3.2472, Loss_D: 0.0682
Iteration 1200: Loss_G: 3.3003, Loss_D: 0.0744
Epoch [2/10], Loss_G: 2.7636, Loss_D: 0.0324
Epoch [3/10] starts
Iteration 50: Loss_G: 3.2299, Loss_D: 0.0751
Iteration 100: Loss_G: 3.1327, Loss_D: 0.0796
Iteration 150: Loss_G: 3.1324, Loss_D: 0.0817
Iteration 200: Loss_G: 3.2778, Loss_D: 0.0778
Iteration 250: Loss_G: 3.2099, Loss_D: 0.0816
Iteration 300: Loss_G: 3.7309, Loss_D: 0.1412
Iteration 350: Loss_G: 3.4070, Loss_D: 0.1052
Iteration 400: Loss_G: 3.4320, Loss_D: 0.0027
Iteration 450: Loss_G: 3.3548, Loss_D: 0.0067
Iteration 500: Loss_G: 3.3337, Loss_D: 0.0156
Iteration 550: Loss_G: 3.2945, Loss_D: 0.0177
Iteration 600: Loss_G: 3.3648, Loss_D: 0.0130
Iteration 650: Loss_G: 3.2823, Loss_D: 0.0031
Iteration 700: Loss_G: 3.2362, Loss_D: 0.0060
Iteration 750: Loss_G: 3.2847, Loss_D: 0.0060
Iteration 800: Loss_G: 3.3505, Loss_D: 0.0059
Iteration 850: Loss_G: 3.1821, Loss_D: 0.0089
Iteration 900: Loss_G: 3.1710, Loss_D: 0.0098
Iteration 950: Loss_G: 3.3288, Loss_D: 0.0152
Iteration 1000: Loss_G: 3.3314, Loss_D: 0.0180
Iteration 1050: Loss_G: 3.4209, Loss_D: 0.0230
Iteration 1100: Loss_G: 3.3184, Loss_D: 0.0014
Iteration 1150: Loss_G: 3.1689, Loss_D: 0.0011
Iteration 1200: Loss_G: 3.1915, Loss_D: 0.0081
Epoch [3/10], Loss_G: 2.7001, Loss_D: 0.0335
Epoch [4/10] starts
Iteration 50: Loss_G: 3.2740, Loss_D: 0.0034
Iteration 100: Loss_G: 3.4078, Loss_D: 0.0053
Iteration 150: Loss_G: 3.2909, Loss_D: 0.0037
Iteration 200: Loss_G: 3.2326, Loss_D: 0.0054
Iteration 250: Loss_G: 3.2447, Loss_D: 0.0067
Iteration 300: Loss_G: 3.1998, Loss_D: 0.0093
Iteration 350: Loss_G: 3.2722, Loss_D: 0.0063
Iteration 400: Loss_G: 3.1981, Loss_D: 0.0068
Iteration 450: Loss_G: 3.3918, Loss_D: 0.0079
Iteration 500: Loss_G: 3.2032, Loss_D: 0.0096
Iteration 550: Loss_G: 3.0732, Loss_D: 0.0116
Iteration 600: Loss_G: 3.2490, Loss_D: 0.0111
Iteration 650: Loss_G: 3.1790, Loss_D: 0.0130
Iteration 700: Loss_G: 3.2166, Loss_D: 0.0149
Iteration 750: Loss_G: 3.2815, Loss_D: 0.0156
Iteration 800: Loss_G: 3.2038, Loss_D: 0.0205
Iteration 850: Loss_G: 3.1341, Loss_D: 0.0233
Iteration 900: Loss_G: 3.3164, Loss_D: 0.0281
Iteration 950: Loss_G: 3.2036, Loss_D: 0.0299
Iteration 1000: Loss_G: 3.4066, Loss_D: 0.0312
Iteration 1050: Loss_G: 3.3609, Loss_D: 0.0340
Iteration 1100: Loss_G: 3.1557, Loss_D: 0.0366
Iteration 1150: Loss_G: 3.2044, Loss_D: 0.0491
Iteration 1200: Loss_G: 3.7643, Loss_D: 0.0173
Epoch [4/10], Loss_G: 2.6761, Loss_D: 0.0167
Epoch [5/10] starts
Iteration 50: Loss_G: 3.2854, Loss_D: 0.0013
Iteration 100: Loss_G: 3.3809, Loss_D: 0.0006
Iteration 150: Loss_G: 3.4302, Loss_D: 0.0006
Iteration 200: Loss_G: 3.2224, Loss_D: 0.0005
Iteration 250: Loss_G: 3.2627, Loss_D: 0.0007
Iteration 300: Loss_G: 3.2402, Loss_D: 0.0027
Iteration 350: Loss_G: 3.1998, Loss_D: 0.0034
Iteration 400: Loss_G: 3.2773, Loss_D: 0.0017
Iteration 450: Loss_G: 3.2088, Loss_D: 0.0027
Iteration 500: Loss_G: 3.2027, Loss_D: 0.0022
Iteration 550: Loss_G: 3.1853, Loss_D: 0.0061
Iteration 600: Loss_G: 3.1698, Loss_D: 0.0081
Iteration 650: Loss_G: 3.3407, Loss_D: 0.0048
Iteration 700: Loss_G: 3.1637, Loss_D: 0.0048
Iteration 750: Loss_G: 3.2495, Loss_D: 0.0050
Iteration 800: Loss_G: 3.1142, Loss_D: 0.0071
Iteration 850: Loss_G: 3.2079, Loss_D: 0.0103
Iteration 900: Loss_G: 3.3100, Loss_D: 0.0111
Iteration 950: Loss_G: 3.1219, Loss_D: 0.0180
Iteration 1000: Loss_G: 3.1595, Loss_D: 0.0130
Iteration 1050: Loss_G: 3.3264, Loss_D: 0.0133
Iteration 1100: Loss_G: 3.3398, Loss_D: 0.0011
Iteration 1150: Loss_G: 3.1529, Loss_D: 0.0011
Iteration 1200: Loss_G: 3.1032, Loss_D: 0.0008
Epoch [5/10], Loss_G: 2.6485, Loss_D: 0.0050
Epoch [6/10] starts
Iteration 50: Loss_G: 3.2865, Loss_D: 0.0003
Iteration 100: Loss_G: 3.1739, Loss_D: 0.0004
Iteration 150: Loss_G: 3.2828, Loss_D: 0.0005
Iteration 200: Loss_G: 3.3240, Loss_D: 0.0004
Iteration 250: Loss_G: 3.2693, Loss_D: 0.0007
Iteration 300: Loss_G: 3.1921, Loss_D: 0.0011
Iteration 350: Loss_G: 3.2165, Loss_D: 0.0005
Iteration 400: Loss_G: 3.1068, Loss_D: 0.0009
Iteration 450: Loss_G: 3.2469, Loss_D: 0.0010
Iteration 500: Loss_G: 3.1781, Loss_D: 0.0005
Iteration 550: Loss_G: 3.0723, Loss_D: 0.0011
Iteration 600: Loss_G: 3.2986, Loss_D: 0.0009
Iteration 650: Loss_G: 3.2211, Loss_D: 0.0006
Iteration 700: Loss_G: 3.2091, Loss_D: 0.0015
Iteration 750: Loss_G: 3.2638, Loss_D: 0.0018
Iteration 800: Loss_G: 3.1623, Loss_D: 0.0022
Iteration 850: Loss_G: 3.2454, Loss_D: 0.0025
Iteration 900: Loss_G: 3.1597, Loss_D: 0.0033
Iteration 950: Loss_G: 3.0685, Loss_D: 0.0007
Iteration 1000: Loss_G: 3.1732, Loss_D: 0.0008
Iteration 1050: Loss_G: 3.2760, Loss_D: 0.0002
Iteration 1100: Loss_G: 3.1143, Loss_D: 0.0005
Iteration 1150: Loss_G: 3.1665, Loss_D: 0.0007
Iteration 1200: Loss_G: 3.1111, Loss_D: 0.0004
Epoch [6/10], Loss_G: 2.6200, Loss_D: 0.0010
Epoch [7/10] starts
Iteration 50: Loss_G: 3.2273, Loss_D: 0.0004
Iteration 100: Loss_G: 3.2025, Loss_D: 0.0005
Iteration 150: Loss_G: 3.1872, Loss_D: 0.0009
Iteration 200: Loss_G: 3.2014, Loss_D: 0.0007
Iteration 250: Loss_G: 3.1518, Loss_D: 0.0007
Iteration 300: Loss_G: 3.1816, Loss_D: 0.0266
Iteration 350: Loss_G: 3.2759, Loss_D: 0.0204
Iteration 400: Loss_G: 3.2420, Loss_D: 0.0030
Iteration 450: Loss_G: 3.1207, Loss_D: 0.0025
Iteration 500: Loss_G: 3.2148, Loss_D: 0.0046
Iteration 550: Loss_G: 3.1235, Loss_D: 0.0029
Iteration 600: Loss_G: 3.1094, Loss_D: 0.0045
Iteration 650: Loss_G: 3.1755, Loss_D: 0.0068
Iteration 700: Loss_G: 3.0469, Loss_D: 0.0052
Iteration 750: Loss_G: 3.0468, Loss_D: 0.0043
Iteration 800: Loss_G: 3.0472, Loss_D: 0.0032
Iteration 850: Loss_G: 3.1525, Loss_D: 0.0036
Iteration 900: Loss_G: 3.0869, Loss_D: 0.0040
Iteration 950: Loss_G: 3.2062, Loss_D: 0.0048
Iteration 1000: Loss_G: 3.0243, Loss_D: 0.0056
Iteration 1050: Loss_G: 3.1563, Loss_D: 0.0050
Iteration 1100: Loss_G: 3.1425, Loss_D: 0.0050
Iteration 1150: Loss_G: 3.0869, Loss_D: 0.0062
Iteration 1200: Loss_G: 3.0688, Loss_D: 0.0066
Epoch [7/10], Loss_G: 2.5743, Loss_D: 0.0054
Epoch [8/10] starts
Iteration 50: Loss_G: 2.9979, Loss_D: 0.0040
Iteration 100: Loss_G: 3.0254, Loss_D: 0.0065
Iteration 150: Loss_G: 2.9759, Loss_D: 0.0067
Iteration 200: Loss_G: 2.9249, Loss_D: 0.0061
Iteration 250: Loss_G: 2.9094, Loss_D: 0.0080
Iteration 300: Loss_G: 2.9347, Loss_D: 0.0075
Iteration 350: Loss_G: 2.8721, Loss_D: 0.0103
Iteration 400: Loss_G: 2.9245, Loss_D: 0.0119
Iteration 450: Loss_G: 3.2507, Loss_D: 0.1246
Iteration 500: Loss_G: 2.9810, Loss_D: 0.2505
Iteration 550: Loss_G: 2.9228, Loss_D: 0.1674
Iteration 600: Loss_G: 2.9476, Loss_D: 0.0004
Iteration 650: Loss_G: 2.9046, Loss_D: 0.0009
Iteration 700: Loss_G: 2.8633, Loss_D: 0.0002
Iteration 750: Loss_G: 2.9122, Loss_D: 0.0004
Iteration 800: Loss_G: 2.8521, Loss_D: 0.0003
Iteration 850: Loss_G: 2.9388, Loss_D: 0.0008
Iteration 900: Loss_G: 2.8515, Loss_D: 0.0007
Iteration 950: Loss_G: 2.8696, Loss_D: 0.0011
Iteration 1000: Loss_G: 2.8808, Loss_D: 0.0023
Iteration 1050: Loss_G: 2.8698, Loss_D: 0.0012
Iteration 1100: Loss_G: 2.8539, Loss_D: 0.0007
Iteration 1150: Loss_G: 2.7901, Loss_D: 0.0006
Iteration 1200: Loss_G: 2.8146, Loss_D: 0.0004
Epoch [8/10], Loss_G: 2.3898, Loss_D: 0.0256
Epoch [9/10] starts
Iteration 50: Loss_G: 2.8512, Loss_D: 0.0005
Iteration 100: Loss_G: 2.8435, Loss_D: 0.0012
Iteration 150: Loss_G: 2.7859, Loss_D: 0.0004
Iteration 200: Loss_G: 2.7698, Loss_D: 0.0004
Iteration 250: Loss_G: 2.7980, Loss_D: 0.0005
Iteration 300: Loss_G: 2.7758, Loss_D: 0.0015
Iteration 350: Loss_G: 2.8049, Loss_D: 0.0005
Iteration 400: Loss_G: 2.8412, Loss_D: 0.0010
Iteration 450: Loss_G: 2.7882, Loss_D: 0.0010
Iteration 500: Loss_G: 2.8935, Loss_D: 0.0012
Iteration 550: Loss_G: 2.8083, Loss_D: 0.0002
Iteration 600: Loss_G: 2.7978, Loss_D: 0.0001
Iteration 650: Loss_G: 2.7766, Loss_D: 0.0000
Iteration 700: Loss_G: 2.7943, Loss_D: 0.0003
Iteration 750: Loss_G: 2.7597, Loss_D: 0.0000
Iteration 800: Loss_G: 2.8741, Loss_D: 0.0000
Iteration 850: Loss_G: 2.7869, Loss_D: 0.0000
Iteration 900: Loss_G: 2.7973, Loss_D: 0.0000
Iteration 950: Loss_G: 2.8236, Loss_D: 0.0002
Iteration 1000: Loss_G: 2.7819, Loss_D: 0.0000
Iteration 1050: Loss_G: 2.8337, Loss_D: 0.0001
Iteration 1100: Loss_G: 2.7744, Loss_D: 0.0000
Iteration 1150: Loss_G: 2.7809, Loss_D: 0.0001
Iteration 1200: Loss_G: 2.7557, Loss_D: 0.0000
Epoch [9/10], Loss_G: 2.2953, Loss_D: 0.0004
Epoch [10/10] starts
Iteration 50: Loss_G: 2.7723, Loss_D: 0.0000
Iteration 100: Loss_G: 2.7983, Loss_D: 0.0000
Iteration 150: Loss_G: 2.7411, Loss_D: 0.0000
Iteration 200: Loss_G: 2.7724, Loss_D: 0.0004
Iteration 250: Loss_G: 2.7370, Loss_D: 0.0005
Iteration 300: Loss_G: 2.7140, Loss_D: 0.0007
Iteration 350: Loss_G: 2.7215, Loss_D: 0.0002
Iteration 400: Loss_G: 2.7398, Loss_D: 0.0000
Iteration 450: Loss_G: 2.7546, Loss_D: 0.0002
Iteration 500: Loss_G: 2.7739, Loss_D: 0.0001
Iteration 550: Loss_G: 2.7865, Loss_D: 0.0001
Iteration 600: Loss_G: 2.7050, Loss_D: 0.0003
Iteration 650: Loss_G: 2.7197, Loss_D: 0.0001
Iteration 700: Loss_G: 2.8215, Loss_D: 0.0001
Iteration 750: Loss_G: 2.7485, Loss_D: 0.0001
Iteration 800: Loss_G: 2.7558, Loss_D: 0.0000
Iteration 850: Loss_G: 2.7522, Loss_D: 0.0000
Iteration 900: Loss_G: 2.7512, Loss_D: 0.0001
Iteration 950: Loss_G: 2.7216, Loss_D: 0.0000
Iteration 1000: Loss_G: 2.7146, Loss_D: 0.0000
Iteration 1050: Loss_G: 2.7516, Loss_D: 0.0000
Iteration 1100: Loss_G: 2.7231, Loss_D: 0.0000
Iteration 1150: Loss_G: 2.8039, Loss_D: 0.0000
Iteration 1200: Loss_G: 2.7248, Loss_D: 0.0001
Epoch [10/10], Loss_G: 2.2512, Loss_D: 0.0001
The process took 19.908998000621796 minutes to complete.
