nohup: ignoring input
Using downloaded and verified file: ./data/SVHN/raw/train_32x32.mat
Using downloaded and verified file: ./data/SVHN/raw/test_32x32.mat
Using device cuda
Training starts
Epoch [1/10] starts
Iteration 50: Loss_G: 1.9994, Loss_D: 0.0848
Iteration 100: Loss_G: 1.4079, Loss_D: 0.1155
Iteration 150: Loss_G: 1.0234, Loss_D: 0.1292
Iteration 200: Loss_G: 0.9538, Loss_D: 0.1232
Iteration 250: Loss_G: 0.9157, Loss_D: 0.1197
Iteration 300: Loss_G: 0.9071, Loss_D: 0.1198
Iteration 350: Loss_G: 0.9311, Loss_D: 0.1206
Iteration 400: Loss_G: 0.9305, Loss_D: 0.1183
Iteration 450: Loss_G: 0.9029, Loss_D: 0.1187
Iteration 500: Loss_G: 0.9060, Loss_D: 0.1190
Iteration 550: Loss_G: 0.9220, Loss_D: 0.1196
Iteration 600: Loss_G: 0.9054, Loss_D: 0.1184
Iteration 650: Loss_G: 0.9248, Loss_D: 0.1197
Iteration 700: Loss_G: 0.9161, Loss_D: 0.1182
Iteration 750: Loss_G: 0.9148, Loss_D: 0.1171
Iteration 800: Loss_G: 0.9228, Loss_D: 0.1171
Iteration 850: Loss_G: 0.9378, Loss_D: 0.1175
Iteration 900: Loss_G: 0.9346, Loss_D: 0.1165
Iteration 950: Loss_G: 0.9075, Loss_D: 0.1189
Iteration 1000: Loss_G: 0.9064, Loss_D: 0.1201
Iteration 1050: Loss_G: 0.8884, Loss_D: 0.1193
Iteration 1100: Loss_G: 0.8984, Loss_D: 0.1189
Iteration 1150: Loss_G: 0.9002, Loss_D: 0.1206
Iteration 1200: Loss_G: 0.8830, Loss_D: 0.1194
Epoch [1/10], Loss_G: 0.8063, Loss_D: 0.1179
Epoch [2/10] starts
Iteration 50: Loss_G: 0.8912, Loss_D: 0.1197
Iteration 100: Loss_G: 0.8950, Loss_D: 0.1212
Iteration 150: Loss_G: 0.8770, Loss_D: 0.1206
Iteration 200: Loss_G: 0.8846, Loss_D: 0.1214
Iteration 250: Loss_G: 0.8583, Loss_D: 0.1218
Iteration 300: Loss_G: 0.8671, Loss_D: 0.1206
Iteration 350: Loss_G: 0.8614, Loss_D: 0.1195
Iteration 400: Loss_G: 0.8698, Loss_D: 0.1193
Iteration 450: Loss_G: 0.8699, Loss_D: 0.1213
Iteration 500: Loss_G: 0.8625, Loss_D: 0.1203
Iteration 550: Loss_G: 0.8647, Loss_D: 0.1215
Iteration 600: Loss_G: 0.8283, Loss_D: 0.1222
Iteration 650: Loss_G: 0.8217, Loss_D: 0.1227
Iteration 700: Loss_G: 0.8284, Loss_D: 0.1210
Iteration 750: Loss_G: 0.8207, Loss_D: 0.1212
Iteration 800: Loss_G: 0.8368, Loss_D: 0.1218
Iteration 850: Loss_G: 0.8214, Loss_D: 0.1207
Iteration 900: Loss_G: 0.8044, Loss_D: 0.1220
Iteration 950: Loss_G: 0.8271, Loss_D: 0.1220
Iteration 1000: Loss_G: 0.8359, Loss_D: 0.1224
Iteration 1050: Loss_G: 0.7914, Loss_D: 0.1210
Iteration 1100: Loss_G: 0.8439, Loss_D: 0.1219
Iteration 1150: Loss_G: 0.8115, Loss_D: 0.1228
Iteration 1200: Loss_G: 0.7938, Loss_D: 0.1219
Epoch [2/10], Loss_G: 0.6912, Loss_D: 0.1213
Epoch [3/10] starts
Iteration 50: Loss_G: 0.8280, Loss_D: 0.1227
Iteration 100: Loss_G: 0.8247, Loss_D: 0.1214
Iteration 150: Loss_G: 0.8015, Loss_D: 0.1227
Iteration 200: Loss_G: 0.7883, Loss_D: 0.1228
Iteration 250: Loss_G: 0.7616, Loss_D: 0.1236
Iteration 300: Loss_G: 0.7723, Loss_D: 0.1245
Iteration 350: Loss_G: 0.7897, Loss_D: 0.1227
Iteration 400: Loss_G: 0.7684, Loss_D: 0.1228
Iteration 450: Loss_G: 0.7792, Loss_D: 0.1218
Iteration 500: Loss_G: 0.8075, Loss_D: 0.1215
Iteration 550: Loss_G: 0.7840, Loss_D: 0.1243
Iteration 600: Loss_G: 0.7648, Loss_D: 0.1233
Iteration 650: Loss_G: 0.7688, Loss_D: 0.1228
Iteration 700: Loss_G: 0.7758, Loss_D: 0.1230
Iteration 750: Loss_G: 0.7867, Loss_D: 0.1222
Iteration 800: Loss_G: 0.7800, Loss_D: 0.1239
Iteration 850: Loss_G: 0.7651, Loss_D: 0.1232
Iteration 900: Loss_G: 0.7830, Loss_D: 0.1230
Iteration 950: Loss_G: 0.7883, Loss_D: 0.1237
Iteration 1000: Loss_G: 0.7737, Loss_D: 0.1227
Iteration 1050: Loss_G: 0.7681, Loss_D: 0.1238
Iteration 1100: Loss_G: 0.7647, Loss_D: 0.1240
Iteration 1150: Loss_G: 0.7634, Loss_D: 0.1242
Iteration 1200: Loss_G: 0.7493, Loss_D: 0.1236
Epoch [3/10], Loss_G: 0.6390, Loss_D: 0.1231
Epoch [4/10] starts
Iteration 50: Loss_G: 0.7663, Loss_D: 0.1231
Iteration 100: Loss_G: 0.7776, Loss_D: 0.1232
Iteration 150: Loss_G: 0.7458, Loss_D: 0.1228
Iteration 200: Loss_G: 0.7649, Loss_D: 0.1234
Iteration 250: Loss_G: 0.7553, Loss_D: 0.1237
Iteration 300: Loss_G: 0.7533, Loss_D: 0.1239
Iteration 350: Loss_G: 0.7350, Loss_D: 0.1239
Iteration 400: Loss_G: 0.7352, Loss_D: 0.1229
Iteration 450: Loss_G: 0.7968, Loss_D: 0.1231
Iteration 500: Loss_G: 0.7871, Loss_D: 0.1230
Iteration 550: Loss_G: 0.7528, Loss_D: 0.1244
Iteration 600: Loss_G: 0.7373, Loss_D: 0.1245
Iteration 650: Loss_G: 0.7453, Loss_D: 0.1235
Iteration 700: Loss_G: 0.7405, Loss_D: 0.1233
Iteration 750: Loss_G: 0.7444, Loss_D: 0.1238
Iteration 800: Loss_G: 0.7518, Loss_D: 0.1242
Iteration 850: Loss_G: 0.7637, Loss_D: 0.1229
Iteration 900: Loss_G: 0.7350, Loss_D: 0.1239
Iteration 950: Loss_G: 0.7531, Loss_D: 0.1244
Iteration 1000: Loss_G: 0.7441, Loss_D: 0.1225
Iteration 1050: Loss_G: 0.7508, Loss_D: 0.1242
Iteration 1100: Loss_G: 0.7286, Loss_D: 0.1234
Iteration 1150: Loss_G: 0.7633, Loss_D: 0.1235
Iteration 1200: Loss_G: 0.7568, Loss_D: 0.1229
Epoch [4/10], Loss_G: 0.6168, Loss_D: 0.1235
Epoch [5/10] starts
Iteration 50: Loss_G: 0.7533, Loss_D: 0.1234
Iteration 100: Loss_G: 0.7392, Loss_D: 0.1241
Iteration 150: Loss_G: 0.7296, Loss_D: 0.1239
Iteration 200: Loss_G: 0.7378, Loss_D: 0.1228
Iteration 250: Loss_G: 0.7352, Loss_D: 0.1243
Iteration 300: Loss_G: 0.7453, Loss_D: 0.1238
Iteration 350: Loss_G: 0.7445, Loss_D: 0.1243
Iteration 400: Loss_G: 0.7351, Loss_D: 0.1248
Iteration 450: Loss_G: 0.7419, Loss_D: 0.1230
Iteration 500: Loss_G: 0.7209, Loss_D: 0.1248
Iteration 550: Loss_G: 0.7173, Loss_D: 0.1237
Iteration 600: Loss_G: 0.7276, Loss_D: 0.1250
Iteration 650: Loss_G: 0.7117, Loss_D: 0.1234
Iteration 700: Loss_G: 0.7293, Loss_D: 0.1226
Iteration 750: Loss_G: 0.7423, Loss_D: 0.1237
Iteration 800: Loss_G: 0.7329, Loss_D: 0.1239
Iteration 850: Loss_G: 0.7357, Loss_D: 0.1238
Iteration 900: Loss_G: 0.7385, Loss_D: 0.1230
Iteration 950: Loss_G: 0.7420, Loss_D: 0.1250
Iteration 1000: Loss_G: 0.7280, Loss_D: 0.1243
Iteration 1050: Loss_G: 0.7372, Loss_D: 0.1235
Iteration 1100: Loss_G: 0.7507, Loss_D: 0.1236
Iteration 1150: Loss_G: 0.7315, Loss_D: 0.1246
Iteration 1200: Loss_G: 0.7232, Loss_D: 0.1232
Epoch [5/10], Loss_G: 0.6013, Loss_D: 0.1239
Epoch [6/10] starts
Iteration 50: Loss_G: 0.7284, Loss_D: 0.1238
Iteration 100: Loss_G: 0.7342, Loss_D: 0.1247
Iteration 150: Loss_G: 0.7382, Loss_D: 0.1248
Iteration 200: Loss_G: 0.7218, Loss_D: 0.1244
Iteration 250: Loss_G: 0.7402, Loss_D: 0.1236
Iteration 300: Loss_G: 0.7254, Loss_D: 0.1246
Iteration 350: Loss_G: 0.7364, Loss_D: 0.1239
Iteration 400: Loss_G: 0.7184, Loss_D: 0.1243
Iteration 450: Loss_G: 0.7311, Loss_D: 0.1238
Iteration 500: Loss_G: 0.7382, Loss_D: 0.1236
Iteration 550: Loss_G: 0.7290, Loss_D: 0.1256
Iteration 600: Loss_G: 0.7202, Loss_D: 0.1235
Iteration 650: Loss_G: 0.7260, Loss_D: 0.1247
Iteration 700: Loss_G: 0.7172, Loss_D: 0.1238
Iteration 750: Loss_G: 0.7469, Loss_D: 0.1238
Iteration 800: Loss_G: 0.7501, Loss_D: 0.1243
Iteration 850: Loss_G: 0.7269, Loss_D: 0.1244
Iteration 900: Loss_G: 0.7232, Loss_D: 0.1235
Iteration 950: Loss_G: 0.7435, Loss_D: 0.1240
Iteration 1000: Loss_G: 0.7373, Loss_D: 0.1236
Iteration 1050: Loss_G: 0.7128, Loss_D: 0.1239
Iteration 1100: Loss_G: 0.7418, Loss_D: 0.1231
Iteration 1150: Loss_G: 0.7326, Loss_D: 0.1247
Iteration 1200: Loss_G: 0.7109, Loss_D: 0.1237
Epoch [6/10], Loss_G: 0.5979, Loss_D: 0.1241
Epoch [7/10] starts
Iteration 50: Loss_G: 0.7218, Loss_D: 0.1247
Iteration 100: Loss_G: 0.7161, Loss_D: 0.1242
Iteration 150: Loss_G: 0.7449, Loss_D: 0.1224
Iteration 200: Loss_G: 0.7260, Loss_D: 0.1251
Iteration 250: Loss_G: 0.7311, Loss_D: 0.1237
Iteration 300: Loss_G: 0.7309, Loss_D: 0.1231
Iteration 350: Loss_G: 0.7361, Loss_D: 0.1242
Iteration 400: Loss_G: 0.7465, Loss_D: 0.1239
Iteration 450: Loss_G: 0.7445, Loss_D: 0.1247
Iteration 500: Loss_G: 0.7235, Loss_D: 0.1254
Iteration 550: Loss_G: 0.7246, Loss_D: 0.1230
Iteration 600: Loss_G: 0.7350, Loss_D: 0.1234
Iteration 650: Loss_G: 0.7091, Loss_D: 0.1243
Iteration 700: Loss_G: 0.7580, Loss_D: 0.1227
Iteration 750: Loss_G: 0.7420, Loss_D: 0.1244
Iteration 800: Loss_G: 0.7172, Loss_D: 0.1236
Iteration 850: Loss_G: 0.7364, Loss_D: 0.1236
Iteration 900: Loss_G: 0.7289, Loss_D: 0.1238
Iteration 950: Loss_G: 0.7423, Loss_D: 0.1233
Iteration 1000: Loss_G: 0.7214, Loss_D: 0.1243
Iteration 1050: Loss_G: 0.7141, Loss_D: 0.1234
Iteration 1100: Loss_G: 0.7368, Loss_D: 0.1244
Iteration 1150: Loss_G: 0.7261, Loss_D: 0.1239
Iteration 1200: Loss_G: 0.7217, Loss_D: 0.1229
Epoch [7/10], Loss_G: 0.5981, Loss_D: 0.1238
Epoch [8/10] starts
Iteration 50: Loss_G: 0.7365, Loss_D: 0.1236
Iteration 100: Loss_G: 0.7414, Loss_D: 0.1246
Iteration 150: Loss_G: 0.7371, Loss_D: 0.1235
Iteration 200: Loss_G: 0.7197, Loss_D: 0.1236
Iteration 250: Loss_G: 0.7406, Loss_D: 0.1245
Iteration 300: Loss_G: 0.7296, Loss_D: 0.1229
Iteration 350: Loss_G: 0.7261, Loss_D: 0.1239
Iteration 400: Loss_G: 0.7184, Loss_D: 0.1248
Iteration 450: Loss_G: 0.7286, Loss_D: 0.1238
Iteration 500: Loss_G: 0.7113, Loss_D: 0.1247
Iteration 550: Loss_G: 0.7252, Loss_D: 0.1234
Iteration 600: Loss_G: 0.7346, Loss_D: 0.1237
Iteration 650: Loss_G: 0.7318, Loss_D: 0.1235
Iteration 700: Loss_G: 0.7355, Loss_D: 0.1242
Iteration 750: Loss_G: 0.7297, Loss_D: 0.1249
Iteration 800: Loss_G: 0.7324, Loss_D: 0.1239
Iteration 850: Loss_G: 0.7403, Loss_D: 0.1247
Iteration 900: Loss_G: 0.7227, Loss_D: 0.1231
Iteration 950: Loss_G: 0.7289, Loss_D: 0.1228
Iteration 1000: Loss_G: 0.7389, Loss_D: 0.1250
Iteration 1050: Loss_G: 0.7315, Loss_D: 0.1246
Iteration 1100: Loss_G: 0.7497, Loss_D: 0.1226
Iteration 1150: Loss_G: 0.7086, Loss_D: 0.1249
Iteration 1200: Loss_G: 0.7275, Loss_D: 0.1233
Epoch [8/10], Loss_G: 0.5978, Loss_D: 0.1239
Epoch [9/10] starts
Iteration 50: Loss_G: 0.7192, Loss_D: 0.1247
Iteration 100: Loss_G: 0.7174, Loss_D: 0.1246
Iteration 150: Loss_G: 0.7077, Loss_D: 0.1234
Iteration 200: Loss_G: 0.7108, Loss_D: 0.1243
Iteration 250: Loss_G: 0.7189, Loss_D: 0.1236
Iteration 300: Loss_G: 0.7418, Loss_D: 0.1240
Iteration 350: Loss_G: 0.7208, Loss_D: 0.1250
Iteration 400: Loss_G: 0.7117, Loss_D: 0.1244
Iteration 450: Loss_G: 0.7268, Loss_D: 0.1245
Iteration 500: Loss_G: 0.7104, Loss_D: 0.1229
Iteration 550: Loss_G: 0.7197, Loss_D: 0.1242
Iteration 600: Loss_G: 0.7305, Loss_D: 0.1228
Iteration 650: Loss_G: 0.7443, Loss_D: 0.1243
Iteration 700: Loss_G: 0.7318, Loss_D: 0.1236
Iteration 750: Loss_G: 0.7300, Loss_D: 0.1238
Iteration 800: Loss_G: 0.7204, Loss_D: 0.1242
Iteration 850: Loss_G: 0.7202, Loss_D: 0.1236
Iteration 900: Loss_G: 0.7319, Loss_D: 0.1237
Iteration 950: Loss_G: 0.7404, Loss_D: 0.1227
Iteration 1000: Loss_G: 0.7432, Loss_D: 0.1231
Iteration 1050: Loss_G: 0.7414, Loss_D: 0.1233
Iteration 1100: Loss_G: 0.7254, Loss_D: 0.1234
Iteration 1150: Loss_G: 0.7192, Loss_D: 0.1238
Iteration 1200: Loss_G: 0.7250, Loss_D: 0.1239
Epoch [9/10], Loss_G: 0.5938, Loss_D: 0.1238
Epoch [10/10] starts
Iteration 50: Loss_G: 0.7305, Loss_D: 0.1233
Iteration 100: Loss_G: 0.7348, Loss_D: 0.1232
Iteration 150: Loss_G: 0.7525, Loss_D: 0.1249
Iteration 200: Loss_G: 0.7522, Loss_D: 0.1233
Iteration 250: Loss_G: 0.7197, Loss_D: 0.1244
Iteration 300: Loss_G: 0.7332, Loss_D: 0.1243
Iteration 350: Loss_G: 0.7325, Loss_D: 0.1239
Iteration 400: Loss_G: 0.7352, Loss_D: 0.1233
Iteration 450: Loss_G: 0.7238, Loss_D: 0.1231
Iteration 500: Loss_G: 0.7393, Loss_D: 0.1233
Iteration 550: Loss_G: 0.7345, Loss_D: 0.1237
Iteration 600: Loss_G: 0.7268, Loss_D: 0.1237
Iteration 650: Loss_G: 0.7287, Loss_D: 0.1237
Iteration 700: Loss_G: 0.7208, Loss_D: 0.1247
Iteration 750: Loss_G: 0.7417, Loss_D: 0.1226
Iteration 800: Loss_G: 0.7645, Loss_D: 0.1241
Iteration 850: Loss_G: 0.7261, Loss_D: 0.1233
Iteration 900: Loss_G: 0.7743, Loss_D: 0.1226
Iteration 950: Loss_G: 0.7256, Loss_D: 0.1242
Iteration 1000: Loss_G: 0.7020, Loss_D: 0.1244
Iteration 1050: Loss_G: 0.7405, Loss_D: 0.1248
Iteration 1100: Loss_G: 0.7169, Loss_D: 0.1244
Iteration 1150: Loss_G: 0.7239, Loss_D: 0.1237
Iteration 1200: Loss_G: 0.7786, Loss_D: 0.1222
Epoch [10/10], Loss_G: 0.6023, Loss_D: 0.1237
The process took 29.724917964140573 minutes to complete.
