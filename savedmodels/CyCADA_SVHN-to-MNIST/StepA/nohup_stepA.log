nohup: ignoring input
Using downloaded and verified file: ./data/SVHN/raw/train/train_32x32.mat
Using downloaded and verified file: ./data/SVHN/raw/test/test_32x32.mat
Train - Iteration 0: 	Loss_stepA: 0.0460
Train - Iteration 50: 	Loss_stepA: 2.2525
Train - Iteration 100: 	Loss_stepA: 2.2064
Train - Iteration 150: 	Loss_stepA: 2.0719
Train - Iteration 200: 	Loss_stepA: 1.8049
Train - Iteration 250: 	Loss_stepA: 1.5252
Train - Iteration 300: 	Loss_stepA: 1.3700
Train - Iteration 350: 	Loss_stepA: 1.2207
Train - Iteration 400: 	Loss_stepA: 1.1322
Train - Iteration 450: 	Loss_stepA: 1.0482
Train - Iteration 500: 	Loss_stepA: 1.0102
Train - Iteration 550: 	Loss_stepA: 0.9619
Train - Epoch [1]: 	Loss_stepA: 1.4884
Test - Epoch [1]: 	Accuracy_stepA: 76.62%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0188
Train - Iteration 50: 	Loss_stepA: 0.8733
Train - Iteration 100: 	Loss_stepA: 0.8592
Train - Iteration 150: 	Loss_stepA: 0.8385
Train - Iteration 200: 	Loss_stepA: 0.8263
Train - Iteration 250: 	Loss_stepA: 0.7770
Train - Iteration 300: 	Loss_stepA: 0.7733
Train - Iteration 350: 	Loss_stepA: 0.7626
Train - Iteration 400: 	Loss_stepA: 0.7297
Train - Iteration 450: 	Loss_stepA: 0.7290
Train - Iteration 500: 	Loss_stepA: 0.7255
Train - Iteration 550: 	Loss_stepA: 0.7029
Train - Epoch [2]: 	Loss_stepA: 0.7786
Test - Epoch [2]: 	Accuracy_stepA: 81.78%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0142
Train - Iteration 50: 	Loss_stepA: 0.6953
Train - Iteration 100: 	Loss_stepA: 0.6663
Train - Iteration 150: 	Loss_stepA: 0.6432
Train - Iteration 200: 	Loss_stepA: 0.6685
Train - Iteration 250: 	Loss_stepA: 0.6510
Train - Iteration 300: 	Loss_stepA: 0.6436
Train - Iteration 350: 	Loss_stepA: 0.6337
Train - Iteration 400: 	Loss_stepA: 0.6172
Train - Iteration 450: 	Loss_stepA: 0.6300
Train - Iteration 500: 	Loss_stepA: 0.6138
Train - Iteration 550: 	Loss_stepA: 0.5814
Train - Epoch [3]: 	Loss_stepA: 0.6385
Test - Epoch [3]: 	Accuracy_stepA: 84.32%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0118
Train - Iteration 50: 	Loss_stepA: 0.5755
Train - Iteration 100: 	Loss_stepA: 0.5889
Train - Iteration 150: 	Loss_stepA: 0.5769
Train - Iteration 200: 	Loss_stepA: 0.5873
Train - Iteration 250: 	Loss_stepA: 0.5678
Train - Iteration 300: 	Loss_stepA: 0.5846
Train - Iteration 350: 	Loss_stepA: 0.5755
Train - Iteration 400: 	Loss_stepA: 0.5750
Train - Iteration 450: 	Loss_stepA: 0.5640
Train - Iteration 500: 	Loss_stepA: 0.5490
Train - Iteration 550: 	Loss_stepA: 0.5550
Train - Epoch [4]: 	Loss_stepA: 0.5716
Test - Epoch [4]: 	Accuracy_stepA: 85.08%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0096
Train - Iteration 50: 	Loss_stepA: 0.5609
Train - Iteration 100: 	Loss_stepA: 0.5277
Train - Iteration 150: 	Loss_stepA: 0.5216
Train - Iteration 200: 	Loss_stepA: 0.5514
Train - Iteration 250: 	Loss_stepA: 0.5356
Train - Iteration 300: 	Loss_stepA: 0.5348
Train - Iteration 350: 	Loss_stepA: 0.5147
Train - Iteration 400: 	Loss_stepA: 0.5040
Train - Iteration 450: 	Loss_stepA: 0.5223
Train - Iteration 500: 	Loss_stepA: 0.4879
Train - Iteration 550: 	Loss_stepA: 0.4917
Train - Epoch [5]: 	Loss_stepA: 0.5222
Test - Epoch [5]: 	Accuracy_stepA: 85.99%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0117
Train - Iteration 50: 	Loss_stepA: 0.4792
Train - Iteration 100: 	Loss_stepA: 0.4920
Train - Iteration 150: 	Loss_stepA: 0.4909
Train - Iteration 200: 	Loss_stepA: 0.4868
Train - Iteration 250: 	Loss_stepA: 0.4928
Train - Iteration 300: 	Loss_stepA: 0.4776
Train - Iteration 350: 	Loss_stepA: 0.5165
Train - Iteration 400: 	Loss_stepA: 0.5036
Train - Iteration 450: 	Loss_stepA: 0.4913
Train - Iteration 500: 	Loss_stepA: 0.4938
Train - Iteration 550: 	Loss_stepA: 0.4594
Train - Epoch [6]: 	Loss_stepA: 0.4883
Test - Epoch [6]: 	Accuracy_stepA: 86.85%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0068
Train - Iteration 50: 	Loss_stepA: 0.4526
Train - Iteration 100: 	Loss_stepA: 0.4953
Train - Iteration 150: 	Loss_stepA: 0.4751
Train - Iteration 200: 	Loss_stepA: 0.4768
Train - Iteration 250: 	Loss_stepA: 0.4640
Train - Iteration 300: 	Loss_stepA: 0.4631
Train - Iteration 350: 	Loss_stepA: 0.4619
Train - Iteration 400: 	Loss_stepA: 0.4662
Train - Iteration 450: 	Loss_stepA: 0.4416
Train - Iteration 500: 	Loss_stepA: 0.4532
Train - Iteration 550: 	Loss_stepA: 0.4253
Train - Epoch [7]: 	Loss_stepA: 0.4615
Test - Epoch [7]: 	Accuracy_stepA: 87.50%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0077
Train - Iteration 50: 	Loss_stepA: 0.4528
Train - Iteration 100: 	Loss_stepA: 0.4437
Train - Iteration 150: 	Loss_stepA: 0.4369
Train - Iteration 200: 	Loss_stepA: 0.4222
Train - Iteration 250: 	Loss_stepA: 0.4470
Train - Iteration 300: 	Loss_stepA: 0.4246
Train - Iteration 350: 	Loss_stepA: 0.4359
Train - Iteration 400: 	Loss_stepA: 0.4497
Train - Iteration 450: 	Loss_stepA: 0.4284
Train - Iteration 500: 	Loss_stepA: 0.4360
Train - Iteration 550: 	Loss_stepA: 0.4380
Train - Epoch [8]: 	Loss_stepA: 0.4389
Test - Epoch [8]: 	Accuracy_stepA: 87.89%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0096
Train - Iteration 50: 	Loss_stepA: 0.4165
Train - Iteration 100: 	Loss_stepA: 0.4093
Train - Iteration 150: 	Loss_stepA: 0.4435
Train - Iteration 200: 	Loss_stepA: 0.4158
Train - Iteration 250: 	Loss_stepA: 0.4343
Train - Iteration 300: 	Loss_stepA: 0.4104
Train - Iteration 350: 	Loss_stepA: 0.4122
Train - Iteration 400: 	Loss_stepA: 0.4194
Train - Iteration 450: 	Loss_stepA: 0.4279
Train - Iteration 500: 	Loss_stepA: 0.4104
Train - Iteration 550: 	Loss_stepA: 0.4137
Train - Epoch [9]: 	Loss_stepA: 0.4185
Test - Epoch [9]: 	Accuracy_stepA: 88.37%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0083
Train - Iteration 50: 	Loss_stepA: 0.4000
Train - Iteration 100: 	Loss_stepA: 0.3954
Train - Iteration 150: 	Loss_stepA: 0.4228
Train - Iteration 200: 	Loss_stepA: 0.4299
Train - Iteration 250: 	Loss_stepA: 0.4061
Train - Iteration 300: 	Loss_stepA: 0.4131
Train - Iteration 350: 	Loss_stepA: 0.3921
Train - Iteration 400: 	Loss_stepA: 0.3937
Train - Iteration 450: 	Loss_stepA: 0.3956
Train - Iteration 500: 	Loss_stepA: 0.3837
Train - Iteration 550: 	Loss_stepA: 0.3857
Train - Epoch [10]: 	Loss_stepA: 0.4032
Test - Epoch [10]: 	Accuracy_stepA: 88.86%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0082
Train - Iteration 50: 	Loss_stepA: 0.3835
Train - Iteration 100: 	Loss_stepA: 0.3859
Train - Iteration 150: 	Loss_stepA: 0.4027
Train - Iteration 200: 	Loss_stepA: 0.3865
Train - Iteration 250: 	Loss_stepA: 0.3891
Train - Iteration 300: 	Loss_stepA: 0.3806
Train - Iteration 350: 	Loss_stepA: 0.3936
Train - Iteration 400: 	Loss_stepA: 0.3812
Train - Iteration 450: 	Loss_stepA: 0.3802
Train - Iteration 500: 	Loss_stepA: 0.3790
Train - Iteration 550: 	Loss_stepA: 0.3934
Train - Epoch [11]: 	Loss_stepA: 0.3862
Test - Epoch [11]: 	Accuracy_stepA: 88.89%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0066
Train - Iteration 50: 	Loss_stepA: 0.3720
Train - Iteration 100: 	Loss_stepA: 0.3613
Train - Iteration 150: 	Loss_stepA: 0.3566
Train - Iteration 200: 	Loss_stepA: 0.3804
Train - Iteration 250: 	Loss_stepA: 0.3785
Train - Iteration 300: 	Loss_stepA: 0.3932
Train - Iteration 350: 	Loss_stepA: 0.3670
Train - Iteration 400: 	Loss_stepA: 0.3705
Train - Iteration 450: 	Loss_stepA: 0.3947
Train - Iteration 500: 	Loss_stepA: 0.3784
Train - Iteration 550: 	Loss_stepA: 0.3945
Train - Epoch [12]: 	Loss_stepA: 0.3768
Test - Epoch [12]: 	Accuracy_stepA: 89.61%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0068
Train - Iteration 50: 	Loss_stepA: 0.3537
Train - Iteration 100: 	Loss_stepA: 0.3622
Train - Iteration 150: 	Loss_stepA: 0.3625
Train - Iteration 200: 	Loss_stepA: 0.3716
Train - Iteration 250: 	Loss_stepA: 0.3530
Train - Iteration 300: 	Loss_stepA: 0.3667
Train - Iteration 350: 	Loss_stepA: 0.3666
Train - Iteration 400: 	Loss_stepA: 0.3626
Train - Iteration 450: 	Loss_stepA: 0.3558
Train - Iteration 500: 	Loss_stepA: 0.3614
Train - Iteration 550: 	Loss_stepA: 0.3797
Train - Epoch [13]: 	Loss_stepA: 0.3633
Test - Epoch [13]: 	Accuracy_stepA: 89.84%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0089
Train - Iteration 50: 	Loss_stepA: 0.3577
Train - Iteration 100: 	Loss_stepA: 0.3550
Train - Iteration 150: 	Loss_stepA: 0.3428
Train - Iteration 200: 	Loss_stepA: 0.3576
Train - Iteration 250: 	Loss_stepA: 0.3743
Train - Iteration 300: 	Loss_stepA: 0.3620
Train - Iteration 350: 	Loss_stepA: 0.3387
Train - Iteration 400: 	Loss_stepA: 0.3572
Train - Iteration 450: 	Loss_stepA: 0.3335
Train - Iteration 500: 	Loss_stepA: 0.3425
Train - Iteration 550: 	Loss_stepA: 0.3537
Train - Epoch [14]: 	Loss_stepA: 0.3531
Test - Epoch [14]: 	Accuracy_stepA: 89.93%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0051
Train - Iteration 50: 	Loss_stepA: 0.3451
Train - Iteration 100: 	Loss_stepA: 0.3423
Train - Iteration 150: 	Loss_stepA: 0.3274
Train - Iteration 200: 	Loss_stepA: 0.3559
Train - Iteration 250: 	Loss_stepA: 0.3402
Train - Iteration 300: 	Loss_stepA: 0.3450
Train - Iteration 350: 	Loss_stepA: 0.3357
Train - Iteration 400: 	Loss_stepA: 0.3421
Train - Iteration 450: 	Loss_stepA: 0.3565
Train - Iteration 500: 	Loss_stepA: 0.3441
Train - Iteration 550: 	Loss_stepA: 0.3350
Train - Epoch [15]: 	Loss_stepA: 0.3430
Test - Epoch [15]: 	Accuracy_stepA: 90.16%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0062
Train - Iteration 50: 	Loss_stepA: 0.3393
Train - Iteration 100: 	Loss_stepA: 0.3487
Train - Iteration 150: 	Loss_stepA: 0.3397
Train - Iteration 200: 	Loss_stepA: 0.3216
Train - Iteration 250: 	Loss_stepA: 0.3289
Train - Iteration 300: 	Loss_stepA: 0.3265
Train - Iteration 350: 	Loss_stepA: 0.3338
Train - Iteration 400: 	Loss_stepA: 0.3187
Train - Iteration 450: 	Loss_stepA: 0.3408
Train - Iteration 500: 	Loss_stepA: 0.3487
Train - Iteration 550: 	Loss_stepA: 0.3478
Train - Epoch [16]: 	Loss_stepA: 0.3358
Test - Epoch [16]: 	Accuracy_stepA: 90.38%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0062
Train - Iteration 50: 	Loss_stepA: 0.3255
Train - Iteration 100: 	Loss_stepA: 0.3275
Train - Iteration 150: 	Loss_stepA: 0.3142
Train - Iteration 200: 	Loss_stepA: 0.3306
Train - Iteration 250: 	Loss_stepA: 0.3339
Train - Iteration 300: 	Loss_stepA: 0.3409
Train - Iteration 350: 	Loss_stepA: 0.3197
Train - Iteration 400: 	Loss_stepA: 0.2971
Train - Iteration 450: 	Loss_stepA: 0.3380
Train - Iteration 500: 	Loss_stepA: 0.3232
Train - Iteration 550: 	Loss_stepA: 0.3270
Train - Epoch [17]: 	Loss_stepA: 0.3251
Test - Epoch [17]: 	Accuracy_stepA: 90.51%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0083
Train - Iteration 50: 	Loss_stepA: 0.3086
Train - Iteration 100: 	Loss_stepA: 0.3292
Train - Iteration 150: 	Loss_stepA: 0.3110
Train - Iteration 200: 	Loss_stepA: 0.2937
Train - Iteration 250: 	Loss_stepA: 0.3184
Train - Iteration 300: 	Loss_stepA: 0.3220
Train - Iteration 350: 	Loss_stepA: 0.3085
Train - Iteration 400: 	Loss_stepA: 0.3293
Train - Iteration 450: 	Loss_stepA: 0.3047
Train - Iteration 500: 	Loss_stepA: 0.3144
Train - Iteration 550: 	Loss_stepA: 0.3370
Train - Epoch [18]: 	Loss_stepA: 0.3162
Test - Epoch [18]: 	Accuracy_stepA: 90.72%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0051
Train - Iteration 50: 	Loss_stepA: 0.3126
Train - Iteration 100: 	Loss_stepA: 0.3144
Train - Iteration 150: 	Loss_stepA: 0.2942
Train - Iteration 200: 	Loss_stepA: 0.3165
Train - Iteration 250: 	Loss_stepA: 0.3188
Train - Iteration 300: 	Loss_stepA: 0.3118
Train - Iteration 350: 	Loss_stepA: 0.3135
Train - Iteration 400: 	Loss_stepA: 0.3101
Train - Iteration 450: 	Loss_stepA: 0.3069
Train - Iteration 500: 	Loss_stepA: 0.3144
Train - Iteration 550: 	Loss_stepA: 0.2898
Train - Epoch [19]: 	Loss_stepA: 0.3097
Test - Epoch [19]: 	Accuracy_stepA: 90.98%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0055
Train - Iteration 50: 	Loss_stepA: 0.3006
Train - Iteration 100: 	Loss_stepA: 0.3115
Train - Iteration 150: 	Loss_stepA: 0.3100
Train - Iteration 200: 	Loss_stepA: 0.2917
Train - Iteration 250: 	Loss_stepA: 0.3059
Train - Iteration 300: 	Loss_stepA: 0.2949
Train - Iteration 350: 	Loss_stepA: 0.3075
Train - Iteration 400: 	Loss_stepA: 0.3015
Train - Iteration 450: 	Loss_stepA: 0.3023
Train - Iteration 500: 	Loss_stepA: 0.3005
Train - Iteration 550: 	Loss_stepA: 0.3272
Train - Epoch [20]: 	Loss_stepA: 0.3051
Test - Epoch [20]: 	Accuracy_stepA: 90.99%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0059
Train - Iteration 50: 	Loss_stepA: 0.2830
Train - Iteration 100: 	Loss_stepA: 0.3049
Train - Iteration 150: 	Loss_stepA: 0.2820
Train - Iteration 200: 	Loss_stepA: 0.2979
Train - Iteration 250: 	Loss_stepA: 0.2942
Train - Iteration 300: 	Loss_stepA: 0.2915
Train - Iteration 350: 	Loss_stepA: 0.2982
Train - Iteration 400: 	Loss_stepA: 0.2943
Train - Iteration 450: 	Loss_stepA: 0.2831
Train - Iteration 500: 	Loss_stepA: 0.3093
Train - Iteration 550: 	Loss_stepA: 0.2990
Train - Epoch [21]: 	Loss_stepA: 0.2953
Test - Epoch [21]: 	Accuracy_stepA: 91.02%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0040
Train - Iteration 50: 	Loss_stepA: 0.2814
Train - Iteration 100: 	Loss_stepA: 0.2967
Train - Iteration 150: 	Loss_stepA: 0.2875
Train - Iteration 200: 	Loss_stepA: 0.2964
Train - Iteration 250: 	Loss_stepA: 0.2947
Train - Iteration 300: 	Loss_stepA: 0.2809
Train - Iteration 350: 	Loss_stepA: 0.2729
Train - Iteration 400: 	Loss_stepA: 0.2784
Train - Iteration 450: 	Loss_stepA: 0.2951
Train - Iteration 500: 	Loss_stepA: 0.2697
Train - Iteration 550: 	Loss_stepA: 0.2910
Train - Epoch [22]: 	Loss_stepA: 0.2859
Test - Epoch [22]: 	Accuracy_stepA: 91.28%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0075
Train - Iteration 50: 	Loss_stepA: 0.2854
Train - Iteration 100: 	Loss_stepA: 0.2983
Train - Iteration 150: 	Loss_stepA: 0.2796
Train - Iteration 200: 	Loss_stepA: 0.2737
Train - Iteration 250: 	Loss_stepA: 0.2708
Train - Iteration 300: 	Loss_stepA: 0.2980
Train - Iteration 350: 	Loss_stepA: 0.2763
Train - Iteration 400: 	Loss_stepA: 0.2812
Train - Iteration 450: 	Loss_stepA: 0.2702
Train - Iteration 500: 	Loss_stepA: 0.2674
Train - Iteration 550: 	Loss_stepA: 0.3072
Train - Epoch [23]: 	Loss_stepA: 0.2836
Test - Epoch [23]: 	Accuracy_stepA: 91.44%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0030
Train - Iteration 50: 	Loss_stepA: 0.2498
Train - Iteration 100: 	Loss_stepA: 0.2767
Train - Iteration 150: 	Loss_stepA: 0.2805
Train - Iteration 200: 	Loss_stepA: 0.2841
Train - Iteration 250: 	Loss_stepA: 0.2648
Train - Iteration 300: 	Loss_stepA: 0.3077
Train - Iteration 350: 	Loss_stepA: 0.2802
Train - Iteration 400: 	Loss_stepA: 0.2770
Train - Iteration 450: 	Loss_stepA: 0.2934
Train - Iteration 500: 	Loss_stepA: 0.2866
Train - Iteration 550: 	Loss_stepA: 0.2729
Train - Epoch [24]: 	Loss_stepA: 0.2793
Test - Epoch [24]: 	Accuracy_stepA: 91.45%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0049
Train - Iteration 50: 	Loss_stepA: 0.2569
Train - Iteration 100: 	Loss_stepA: 0.2800
Train - Iteration 150: 	Loss_stepA: 0.2773
Train - Iteration 200: 	Loss_stepA: 0.2735
Train - Iteration 250: 	Loss_stepA: 0.2801
Train - Iteration 300: 	Loss_stepA: 0.2855
Train - Iteration 350: 	Loss_stepA: 0.2698
Train - Iteration 400: 	Loss_stepA: 0.2802
Train - Iteration 450: 	Loss_stepA: 0.2561
Train - Iteration 500: 	Loss_stepA: 0.2464
Train - Iteration 550: 	Loss_stepA: 0.2702
Train - Epoch [25]: 	Loss_stepA: 0.2708
Test - Epoch [25]: 	Accuracy_stepA: 91.54%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0067
Train - Iteration 50: 	Loss_stepA: 0.2538
Train - Iteration 100: 	Loss_stepA: 0.2830
Train - Iteration 150: 	Loss_stepA: 0.2737
Train - Iteration 200: 	Loss_stepA: 0.2611
Train - Iteration 250: 	Loss_stepA: 0.2543
Train - Iteration 300: 	Loss_stepA: 0.2546
Train - Iteration 350: 	Loss_stepA: 0.2741
Train - Iteration 400: 	Loss_stepA: 0.2813
Train - Iteration 450: 	Loss_stepA: 0.2500
Train - Iteration 500: 	Loss_stepA: 0.2525
Train - Iteration 550: 	Loss_stepA: 0.2717
Train - Epoch [26]: 	Loss_stepA: 0.2647
Test - Epoch [26]: 	Accuracy_stepA: 91.65%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0057
Train - Iteration 50: 	Loss_stepA: 0.2485
Train - Iteration 100: 	Loss_stepA: 0.2688
Train - Iteration 150: 	Loss_stepA: 0.2284
Train - Iteration 200: 	Loss_stepA: 0.2568
Train - Iteration 250: 	Loss_stepA: 0.2605
Train - Iteration 300: 	Loss_stepA: 0.2758
Train - Iteration 350: 	Loss_stepA: 0.2624
Train - Iteration 400: 	Loss_stepA: 0.2878
Train - Iteration 450: 	Loss_stepA: 0.2652
Train - Iteration 500: 	Loss_stepA: 0.2527
Train - Iteration 550: 	Loss_stepA: 0.2649
Train - Epoch [27]: 	Loss_stepA: 0.2605
Test - Epoch [27]: 	Accuracy_stepA: 91.83%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0048
Train - Iteration 50: 	Loss_stepA: 0.2601
Train - Iteration 100: 	Loss_stepA: 0.2444
Train - Iteration 150: 	Loss_stepA: 0.2583
Train - Iteration 200: 	Loss_stepA: 0.2672
Train - Iteration 250: 	Loss_stepA: 0.2499
Train - Iteration 300: 	Loss_stepA: 0.2532
Train - Iteration 350: 	Loss_stepA: 0.2606
Train - Iteration 400: 	Loss_stepA: 0.2549
Train - Iteration 450: 	Loss_stepA: 0.2509
Train - Iteration 500: 	Loss_stepA: 0.2537
Train - Iteration 550: 	Loss_stepA: 0.2520
Train - Epoch [28]: 	Loss_stepA: 0.2557
Test - Epoch [28]: 	Accuracy_stepA: 91.81%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0057
Train - Iteration 50: 	Loss_stepA: 0.2571
Train - Iteration 100: 	Loss_stepA: 0.2475
Train - Iteration 150: 	Loss_stepA: 0.2447
Train - Iteration 200: 	Loss_stepA: 0.2433
Train - Iteration 250: 	Loss_stepA: 0.2496
Train - Iteration 300: 	Loss_stepA: 0.2434
Train - Iteration 350: 	Loss_stepA: 0.2579
Train - Iteration 400: 	Loss_stepA: 0.2471
Train - Iteration 450: 	Loss_stepA: 0.2714
Train - Iteration 500: 	Loss_stepA: 0.2494
Train - Iteration 550: 	Loss_stepA: 0.2670
Train - Epoch [29]: 	Loss_stepA: 0.2522
Test - Epoch [29]: 	Accuracy_stepA: 91.73%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0030
Train - Iteration 50: 	Loss_stepA: 0.2452
Train - Iteration 100: 	Loss_stepA: 0.2603
Train - Iteration 150: 	Loss_stepA: 0.2260
Train - Iteration 200: 	Loss_stepA: 0.2344
Train - Iteration 250: 	Loss_stepA: 0.2599
Train - Iteration 300: 	Loss_stepA: 0.2539
Train - Iteration 350: 	Loss_stepA: 0.2674
Train - Iteration 400: 	Loss_stepA: 0.2402
Train - Iteration 450: 	Loss_stepA: 0.2677
Train - Iteration 500: 	Loss_stepA: 0.2434
Train - Iteration 550: 	Loss_stepA: 0.2547
Train - Epoch [30]: 	Loss_stepA: 0.2493
Test - Epoch [30]: 	Accuracy_stepA: 91.98%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0030
Train - Iteration 50: 	Loss_stepA: 0.2490
Train - Iteration 100: 	Loss_stepA: 0.2504
Train - Iteration 150: 	Loss_stepA: 0.2319
Train - Iteration 200: 	Loss_stepA: 0.2371
Train - Iteration 250: 	Loss_stepA: 0.2530
Train - Iteration 300: 	Loss_stepA: 0.2433
Train - Iteration 350: 	Loss_stepA: 0.2316
Train - Iteration 400: 	Loss_stepA: 0.2391
Train - Iteration 450: 	Loss_stepA: 0.2308
Train - Iteration 500: 	Loss_stepA: 0.2368
Train - Iteration 550: 	Loss_stepA: 0.2488
Train - Epoch [31]: 	Loss_stepA: 0.2428
Test - Epoch [31]: 	Accuracy_stepA: 92.05%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0057
Train - Iteration 50: 	Loss_stepA: 0.2405
Train - Iteration 100: 	Loss_stepA: 0.2309
Train - Iteration 150: 	Loss_stepA: 0.2437
Train - Iteration 200: 	Loss_stepA: 0.2429
Train - Iteration 250: 	Loss_stepA: 0.2379
Train - Iteration 300: 	Loss_stepA: 0.2381
Train - Iteration 350: 	Loss_stepA: 0.2496
Train - Iteration 400: 	Loss_stepA: 0.2378
Train - Iteration 450: 	Loss_stepA: 0.2263
Train - Iteration 500: 	Loss_stepA: 0.2419
Train - Iteration 550: 	Loss_stepA: 0.2560
Train - Epoch [32]: 	Loss_stepA: 0.2410
Test - Epoch [32]: 	Accuracy_stepA: 92.21%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0036
Train - Iteration 50: 	Loss_stepA: 0.2202
Train - Iteration 100: 	Loss_stepA: 0.2374
Train - Iteration 150: 	Loss_stepA: 0.2407
Train - Iteration 200: 	Loss_stepA: 0.2249
Train - Iteration 250: 	Loss_stepA: 0.2321
Train - Iteration 300: 	Loss_stepA: 0.2361
Train - Iteration 350: 	Loss_stepA: 0.2519
Train - Iteration 400: 	Loss_stepA: 0.2375
Train - Iteration 450: 	Loss_stepA: 0.2399
Train - Iteration 500: 	Loss_stepA: 0.2331
Train - Iteration 550: 	Loss_stepA: 0.2291
Train - Epoch [33]: 	Loss_stepA: 0.2353
Test - Epoch [33]: 	Accuracy_stepA: 92.35%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0055
Train - Iteration 50: 	Loss_stepA: 0.2341
Train - Iteration 100: 	Loss_stepA: 0.2188
Train - Iteration 150: 	Loss_stepA: 0.2405
Train - Iteration 200: 	Loss_stepA: 0.2225
Train - Iteration 250: 	Loss_stepA: 0.2169
Train - Iteration 300: 	Loss_stepA: 0.2374
Train - Iteration 350: 	Loss_stepA: 0.2326
Train - Iteration 400: 	Loss_stepA: 0.2293
Train - Iteration 450: 	Loss_stepA: 0.2325
Train - Iteration 500: 	Loss_stepA: 0.2320
Train - Iteration 550: 	Loss_stepA: 0.2337
Train - Epoch [34]: 	Loss_stepA: 0.2306
Test - Epoch [34]: 	Accuracy_stepA: 92.29%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0035
Train - Iteration 50: 	Loss_stepA: 0.2335
Train - Iteration 100: 	Loss_stepA: 0.2328
Train - Iteration 150: 	Loss_stepA: 0.2105
Train - Iteration 200: 	Loss_stepA: 0.2212
Train - Iteration 250: 	Loss_stepA: 0.2376
Train - Iteration 300: 	Loss_stepA: 0.2211
Train - Iteration 350: 	Loss_stepA: 0.2179
Train - Iteration 400: 	Loss_stepA: 0.2317
Train - Iteration 450: 	Loss_stepA: 0.2272
Train - Iteration 500: 	Loss_stepA: 0.2199
Train - Iteration 550: 	Loss_stepA: 0.2314
Train - Epoch [35]: 	Loss_stepA: 0.2262
Test - Epoch [35]: 	Accuracy_stepA: 92.32%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0046
Train - Iteration 50: 	Loss_stepA: 0.2213
Train - Iteration 100: 	Loss_stepA: 0.2073
Train - Iteration 150: 	Loss_stepA: 0.2235
Train - Iteration 200: 	Loss_stepA: 0.2452
Train - Iteration 250: 	Loss_stepA: 0.2364
Train - Iteration 300: 	Loss_stepA: 0.2295
Train - Iteration 350: 	Loss_stepA: 0.2257
Train - Iteration 400: 	Loss_stepA: 0.2113
Train - Iteration 450: 	Loss_stepA: 0.2378
Train - Iteration 500: 	Loss_stepA: 0.2326
Train - Iteration 550: 	Loss_stepA: 0.2220
Train - Epoch [36]: 	Loss_stepA: 0.2256
Test - Epoch [36]: 	Accuracy_stepA: 92.42%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0039
Train - Iteration 50: 	Loss_stepA: 0.2207
Train - Iteration 100: 	Loss_stepA: 0.2175
Train - Iteration 150: 	Loss_stepA: 0.2172
Train - Iteration 200: 	Loss_stepA: 0.2081
Train - Iteration 250: 	Loss_stepA: 0.2143
Train - Iteration 300: 	Loss_stepA: 0.2322
Train - Iteration 350: 	Loss_stepA: 0.2139
Train - Iteration 400: 	Loss_stepA: 0.2178
Train - Iteration 450: 	Loss_stepA: 0.2129
Train - Iteration 500: 	Loss_stepA: 0.2250
Train - Iteration 550: 	Loss_stepA: 0.2245
Train - Epoch [37]: 	Loss_stepA: 0.2186
Test - Epoch [37]: 	Accuracy_stepA: 92.41%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0051
Train - Iteration 50: 	Loss_stepA: 0.2098
Train - Iteration 100: 	Loss_stepA: 0.1901
Train - Iteration 150: 	Loss_stepA: 0.2212
Train - Iteration 200: 	Loss_stepA: 0.2215
Train - Iteration 250: 	Loss_stepA: 0.2224
Train - Iteration 300: 	Loss_stepA: 0.2163
Train - Iteration 350: 	Loss_stepA: 0.2087
Train - Iteration 400: 	Loss_stepA: 0.2283
Train - Iteration 450: 	Loss_stepA: 0.2085
Train - Iteration 500: 	Loss_stepA: 0.2258
Train - Iteration 550: 	Loss_stepA: 0.2321
Train - Epoch [38]: 	Loss_stepA: 0.2170
Test - Epoch [38]: 	Accuracy_stepA: 92.44%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0035
Train - Iteration 50: 	Loss_stepA: 0.2084
Train - Iteration 100: 	Loss_stepA: 0.2019
Train - Iteration 150: 	Loss_stepA: 0.2100
Train - Iteration 200: 	Loss_stepA: 0.2023
Train - Iteration 250: 	Loss_stepA: 0.2186
Train - Iteration 300: 	Loss_stepA: 0.2173
Train - Iteration 350: 	Loss_stepA: 0.2032
Train - Iteration 400: 	Loss_stepA: 0.2074
Train - Iteration 450: 	Loss_stepA: 0.2275
Train - Iteration 500: 	Loss_stepA: 0.2125
Train - Iteration 550: 	Loss_stepA: 0.2094
Train - Epoch [39]: 	Loss_stepA: 0.2119
Test - Epoch [39]: 	Accuracy_stepA: 92.47%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0055
Train - Iteration 50: 	Loss_stepA: 0.2050
Train - Iteration 100: 	Loss_stepA: 0.2047
Train - Iteration 150: 	Loss_stepA: 0.2044
Train - Iteration 200: 	Loss_stepA: 0.1924
Train - Iteration 250: 	Loss_stepA: 0.2010
Train - Iteration 300: 	Loss_stepA: 0.2126
Train - Iteration 350: 	Loss_stepA: 0.1986
Train - Iteration 400: 	Loss_stepA: 0.2161
Train - Iteration 450: 	Loss_stepA: 0.2114
Train - Iteration 500: 	Loss_stepA: 0.2138
Train - Iteration 550: 	Loss_stepA: 0.2183
Train - Epoch [40]: 	Loss_stepA: 0.2073
Test - Epoch [40]: 	Accuracy_stepA: 92.46%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0060
Train - Iteration 50: 	Loss_stepA: 0.2146
Train - Iteration 100: 	Loss_stepA: 0.1937
Train - Iteration 150: 	Loss_stepA: 0.1933
Train - Iteration 200: 	Loss_stepA: 0.2107
Train - Iteration 250: 	Loss_stepA: 0.2095
Train - Iteration 300: 	Loss_stepA: 0.1993
Train - Iteration 350: 	Loss_stepA: 0.2050
Train - Iteration 400: 	Loss_stepA: 0.2021
Train - Iteration 450: 	Loss_stepA: 0.2242
Train - Iteration 500: 	Loss_stepA: 0.1971
Train - Iteration 550: 	Loss_stepA: 0.2022
Train - Epoch [41]: 	Loss_stepA: 0.2050
Test - Epoch [41]: 	Accuracy_stepA: 92.52%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0032
Train - Iteration 50: 	Loss_stepA: 0.1966
Train - Iteration 100: 	Loss_stepA: 0.1896
Train - Iteration 150: 	Loss_stepA: 0.2042
Train - Iteration 200: 	Loss_stepA: 0.2043
Train - Iteration 250: 	Loss_stepA: 0.1830
Train - Iteration 300: 	Loss_stepA: 0.2070
Train - Iteration 350: 	Loss_stepA: 0.2167
Train - Iteration 400: 	Loss_stepA: 0.1981
Train - Iteration 450: 	Loss_stepA: 0.2137
Train - Iteration 500: 	Loss_stepA: 0.1949
Train - Iteration 550: 	Loss_stepA: 0.2177
Train - Epoch [42]: 	Loss_stepA: 0.2023
Test - Epoch [42]: 	Accuracy_stepA: 92.70%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0061
Train - Iteration 50: 	Loss_stepA: 0.1898
Train - Iteration 100: 	Loss_stepA: 0.1980
Train - Iteration 150: 	Loss_stepA: 0.1808
Train - Iteration 200: 	Loss_stepA: 0.1961
Train - Iteration 250: 	Loss_stepA: 0.1942
Train - Iteration 300: 	Loss_stepA: 0.1977
Train - Iteration 350: 	Loss_stepA: 0.2140
Train - Iteration 400: 	Loss_stepA: 0.2045
Train - Iteration 450: 	Loss_stepA: 0.2043
Train - Iteration 500: 	Loss_stepA: 0.2024
Train - Iteration 550: 	Loss_stepA: 0.2004
Train - Epoch [43]: 	Loss_stepA: 0.1986
Test - Epoch [43]: 	Accuracy_stepA: 92.72%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0039
Train - Iteration 50: 	Loss_stepA: 0.1957
Train - Iteration 100: 	Loss_stepA: 0.1977
Train - Iteration 150: 	Loss_stepA: 0.1909
Train - Iteration 200: 	Loss_stepA: 0.1804
Train - Iteration 250: 	Loss_stepA: 0.1947
Train - Iteration 300: 	Loss_stepA: 0.2131
Train - Iteration 350: 	Loss_stepA: 0.2062
Train - Iteration 400: 	Loss_stepA: 0.1878
Train - Iteration 450: 	Loss_stepA: 0.1875
Train - Iteration 500: 	Loss_stepA: 0.2029
Train - Iteration 550: 	Loss_stepA: 0.1901
Train - Epoch [44]: 	Loss_stepA: 0.1958
Test - Epoch [44]: 	Accuracy_stepA: 92.64%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0035
Train - Iteration 50: 	Loss_stepA: 0.1839
Train - Iteration 100: 	Loss_stepA: 0.1918
Train - Iteration 150: 	Loss_stepA: 0.1851
Train - Iteration 200: 	Loss_stepA: 0.1918
Train - Iteration 250: 	Loss_stepA: 0.1981
Train - Iteration 300: 	Loss_stepA: 0.1986
Train - Iteration 350: 	Loss_stepA: 0.2018
Train - Iteration 400: 	Loss_stepA: 0.1951
Train - Iteration 450: 	Loss_stepA: 0.1989
Train - Iteration 500: 	Loss_stepA: 0.1846
Train - Iteration 550: 	Loss_stepA: 0.2012
Train - Epoch [45]: 	Loss_stepA: 0.1948
Test - Epoch [45]: 	Accuracy_stepA: 92.79%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0036
Train - Iteration 50: 	Loss_stepA: 0.1819
Train - Iteration 100: 	Loss_stepA: 0.1857
Train - Iteration 150: 	Loss_stepA: 0.1961
Train - Iteration 200: 	Loss_stepA: 0.1899
Train - Iteration 250: 	Loss_stepA: 0.2040
Train - Iteration 300: 	Loss_stepA: 0.1940
Train - Iteration 350: 	Loss_stepA: 0.1950
Train - Iteration 400: 	Loss_stepA: 0.1857
Train - Iteration 450: 	Loss_stepA: 0.1854
Train - Iteration 500: 	Loss_stepA: 0.1981
Train - Iteration 550: 	Loss_stepA: 0.1881
Train - Epoch [46]: 	Loss_stepA: 0.1923
Test - Epoch [46]: 	Accuracy_stepA: 92.79%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0039
Train - Iteration 50: 	Loss_stepA: 0.1894
Train - Iteration 100: 	Loss_stepA: 0.1713
Train - Iteration 150: 	Loss_stepA: 0.1852
Train - Iteration 200: 	Loss_stepA: 0.1796
Train - Iteration 250: 	Loss_stepA: 0.1969
Train - Iteration 300: 	Loss_stepA: 0.1854
Train - Iteration 350: 	Loss_stepA: 0.2000
Train - Iteration 400: 	Loss_stepA: 0.1928
Train - Iteration 450: 	Loss_stepA: 0.2017
Train - Iteration 500: 	Loss_stepA: 0.1797
Train - Iteration 550: 	Loss_stepA: 0.1966
Train - Epoch [47]: 	Loss_stepA: 0.1884
Test - Epoch [47]: 	Accuracy_stepA: 92.79%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0040
Train - Iteration 50: 	Loss_stepA: 0.1773
Train - Iteration 100: 	Loss_stepA: 0.1871
Train - Iteration 150: 	Loss_stepA: 0.1841
Train - Iteration 200: 	Loss_stepA: 0.1905
Train - Iteration 250: 	Loss_stepA: 0.1922
Train - Iteration 300: 	Loss_stepA: 0.1867
Train - Iteration 350: 	Loss_stepA: 0.1651
Train - Iteration 400: 	Loss_stepA: 0.1879
Train - Iteration 450: 	Loss_stepA: 0.1806
Train - Iteration 500: 	Loss_stepA: 0.1978
Train - Iteration 550: 	Loss_stepA: 0.1804
Train - Epoch [48]: 	Loss_stepA: 0.1861
Test - Epoch [48]: 	Accuracy_stepA: 92.84%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0024
Train - Iteration 50: 	Loss_stepA: 0.1879
Train - Iteration 100: 	Loss_stepA: 0.1756
Train - Iteration 150: 	Loss_stepA: 0.1858
Train - Iteration 200: 	Loss_stepA: 0.1848
Train - Iteration 250: 	Loss_stepA: 0.1809
Train - Iteration 300: 	Loss_stepA: 0.1847
Train - Iteration 350: 	Loss_stepA: 0.1849
Train - Iteration 400: 	Loss_stepA: 0.1669
Train - Iteration 450: 	Loss_stepA: 0.1986
Train - Iteration 500: 	Loss_stepA: 0.1871
Train - Iteration 550: 	Loss_stepA: 0.1889
Train - Epoch [49]: 	Loss_stepA: 0.1848
Test - Epoch [49]: 	Accuracy_stepA: 92.78%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0041
Train - Iteration 50: 	Loss_stepA: 0.1759
Train - Iteration 100: 	Loss_stepA: 0.1807
Train - Iteration 150: 	Loss_stepA: 0.1701
Train - Iteration 200: 	Loss_stepA: 0.1839
Train - Iteration 250: 	Loss_stepA: 0.1890
Train - Iteration 300: 	Loss_stepA: 0.1795
Train - Iteration 350: 	Loss_stepA: 0.1777
Train - Iteration 400: 	Loss_stepA: 0.1698
Train - Iteration 450: 	Loss_stepA: 0.1912
Train - Iteration 500: 	Loss_stepA: 0.1625
Train - Iteration 550: 	Loss_stepA: 0.1945
Train - Epoch [50]: 	Loss_stepA: 0.1803
Test - Epoch [50]: 	Accuracy_stepA: 92.89%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0033
Train - Iteration 50: 	Loss_stepA: 0.1716
Train - Iteration 100: 	Loss_stepA: 0.1814
Train - Iteration 150: 	Loss_stepA: 0.1774
Train - Iteration 200: 	Loss_stepA: 0.1683
Train - Iteration 250: 	Loss_stepA: 0.1832
Train - Iteration 300: 	Loss_stepA: 0.1898
Train - Iteration 350: 	Loss_stepA: 0.1778
Train - Iteration 400: 	Loss_stepA: 0.1825
Train - Iteration 450: 	Loss_stepA: 0.1706
Train - Iteration 500: 	Loss_stepA: 0.1759
Train - Iteration 550: 	Loss_stepA: 0.1814
Train - Epoch [51]: 	Loss_stepA: 0.1779
Test - Epoch [51]: 	Accuracy_stepA: 92.83%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0035
Train - Iteration 50: 	Loss_stepA: 0.1596
Train - Iteration 100: 	Loss_stepA: 0.1774
Train - Iteration 150: 	Loss_stepA: 0.1740
Train - Iteration 200: 	Loss_stepA: 0.1799
Train - Iteration 250: 	Loss_stepA: 0.1771
Train - Iteration 300: 	Loss_stepA: 0.1751
Train - Iteration 350: 	Loss_stepA: 0.1681
Train - Iteration 400: 	Loss_stepA: 0.1809
Train - Iteration 450: 	Loss_stepA: 0.1685
Train - Iteration 500: 	Loss_stepA: 0.1814
Train - Iteration 550: 	Loss_stepA: 0.1866
Train - Epoch [52]: 	Loss_stepA: 0.1755
Test - Epoch [52]: 	Accuracy_stepA: 92.87%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0037
Train - Iteration 50: 	Loss_stepA: 0.1749
Train - Iteration 100: 	Loss_stepA: 0.1591
Train - Iteration 150: 	Loss_stepA: 0.1824
Train - Iteration 200: 	Loss_stepA: 0.1802
Train - Iteration 250: 	Loss_stepA: 0.1681
Train - Iteration 300: 	Loss_stepA: 0.1587
Train - Iteration 350: 	Loss_stepA: 0.1613
Train - Iteration 400: 	Loss_stepA: 0.1711
Train - Iteration 450: 	Loss_stepA: 0.1831
Train - Iteration 500: 	Loss_stepA: 0.1702
Train - Iteration 550: 	Loss_stepA: 0.1666
Train - Epoch [53]: 	Loss_stepA: 0.1713
Test - Epoch [53]: 	Accuracy_stepA: 93.02%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0031
Train - Iteration 50: 	Loss_stepA: 0.1564
Train - Iteration 100: 	Loss_stepA: 0.1663
Train - Iteration 150: 	Loss_stepA: 0.1636
Train - Iteration 200: 	Loss_stepA: 0.1667
Train - Iteration 250: 	Loss_stepA: 0.1625
Train - Iteration 300: 	Loss_stepA: 0.1792
Train - Iteration 350: 	Loss_stepA: 0.1580
Train - Iteration 400: 	Loss_stepA: 0.1745
Train - Iteration 450: 	Loss_stepA: 0.1797
Train - Iteration 500: 	Loss_stepA: 0.1749
Train - Iteration 550: 	Loss_stepA: 0.1808
Train - Epoch [54]: 	Loss_stepA: 0.1691
Test - Epoch [54]: 	Accuracy_stepA: 92.92%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0037
Train - Iteration 50: 	Loss_stepA: 0.1722
Train - Iteration 100: 	Loss_stepA: 0.1620
Train - Iteration 150: 	Loss_stepA: 0.1633
Train - Iteration 200: 	Loss_stepA: 0.1670
Train - Iteration 250: 	Loss_stepA: 0.1597
Train - Iteration 300: 	Loss_stepA: 0.1610
Train - Iteration 350: 	Loss_stepA: 0.1742
Train - Iteration 400: 	Loss_stepA: 0.1826
Train - Iteration 450: 	Loss_stepA: 0.1645
Train - Iteration 500: 	Loss_stepA: 0.1657
Train - Iteration 550: 	Loss_stepA: 0.1780
Train - Epoch [55]: 	Loss_stepA: 0.1678
Test - Epoch [55]: 	Accuracy_stepA: 92.95%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0058
Train - Iteration 50: 	Loss_stepA: 0.1813
Train - Iteration 100: 	Loss_stepA: 0.1699
Train - Iteration 150: 	Loss_stepA: 0.1670
Train - Iteration 200: 	Loss_stepA: 0.1601
Train - Iteration 250: 	Loss_stepA: 0.1631
Train - Iteration 300: 	Loss_stepA: 0.1712
Train - Iteration 350: 	Loss_stepA: 0.1599
Train - Iteration 400: 	Loss_stepA: 0.1549
Train - Iteration 450: 	Loss_stepA: 0.1659
Train - Iteration 500: 	Loss_stepA: 0.1718
Train - Iteration 550: 	Loss_stepA: 0.1766
Train - Epoch [56]: 	Loss_stepA: 0.1666
Test - Epoch [56]: 	Accuracy_stepA: 93.04%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0039
Train - Iteration 50: 	Loss_stepA: 0.1594
Train - Iteration 100: 	Loss_stepA: 0.1593
Train - Iteration 150: 	Loss_stepA: 0.1603
Train - Iteration 200: 	Loss_stepA: 0.1538
Train - Iteration 250: 	Loss_stepA: 0.1551
Train - Iteration 300: 	Loss_stepA: 0.1624
Train - Iteration 350: 	Loss_stepA: 0.1659
Train - Iteration 400: 	Loss_stepA: 0.1649
Train - Iteration 450: 	Loss_stepA: 0.1804
Train - Iteration 500: 	Loss_stepA: 0.1652
Train - Iteration 550: 	Loss_stepA: 0.1799
Train - Epoch [57]: 	Loss_stepA: 0.1648
Test - Epoch [57]: 	Accuracy_stepA: 92.99%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0038
Train - Iteration 50: 	Loss_stepA: 0.1425
Train - Iteration 100: 	Loss_stepA: 0.1448
Train - Iteration 150: 	Loss_stepA: 0.1750
Train - Iteration 200: 	Loss_stepA: 0.1535
Train - Iteration 250: 	Loss_stepA: 0.1555
Train - Iteration 300: 	Loss_stepA: 0.1659
Train - Iteration 350: 	Loss_stepA: 0.1692
Train - Iteration 400: 	Loss_stepA: 0.1700
Train - Iteration 450: 	Loss_stepA: 0.1716
Train - Iteration 500: 	Loss_stepA: 0.1558
Train - Iteration 550: 	Loss_stepA: 0.1659
Train - Epoch [58]: 	Loss_stepA: 0.1608
Test - Epoch [58]: 	Accuracy_stepA: 93.02%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0036
Train - Iteration 50: 	Loss_stepA: 0.1538
Train - Iteration 100: 	Loss_stepA: 0.1574
Train - Iteration 150: 	Loss_stepA: 0.1542
Train - Iteration 200: 	Loss_stepA: 0.1647
Train - Iteration 250: 	Loss_stepA: 0.1578
Train - Iteration 300: 	Loss_stepA: 0.1605
Train - Iteration 350: 	Loss_stepA: 0.1571
Train - Iteration 400: 	Loss_stepA: 0.1784
Train - Iteration 450: 	Loss_stepA: 0.1581
Train - Iteration 500: 	Loss_stepA: 0.1514
Train - Iteration 550: 	Loss_stepA: 0.1562
Train - Epoch [59]: 	Loss_stepA: 0.1584
Test - Epoch [59]: 	Accuracy_stepA: 93.25%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0019
Train - Iteration 50: 	Loss_stepA: 0.1526
Train - Iteration 100: 	Loss_stepA: 0.1584
Train - Iteration 150: 	Loss_stepA: 0.1469
Train - Iteration 200: 	Loss_stepA: 0.1677
Train - Iteration 250: 	Loss_stepA: 0.1605
Train - Iteration 300: 	Loss_stepA: 0.1457
Train - Iteration 350: 	Loss_stepA: 0.1537
Train - Iteration 400: 	Loss_stepA: 0.1457
Train - Iteration 450: 	Loss_stepA: 0.1605
Train - Iteration 500: 	Loss_stepA: 0.1573
Train - Iteration 550: 	Loss_stepA: 0.1521
Train - Epoch [60]: 	Loss_stepA: 0.1552
Test - Epoch [60]: 	Accuracy_stepA: 93.17%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0031
Train - Iteration 50: 	Loss_stepA: 0.1419
Train - Iteration 100: 	Loss_stepA: 0.1504
Train - Iteration 150: 	Loss_stepA: 0.1500
Train - Iteration 200: 	Loss_stepA: 0.1499
Train - Iteration 250: 	Loss_stepA: 0.1486
Train - Iteration 300: 	Loss_stepA: 0.1561
Train - Iteration 350: 	Loss_stepA: 0.1576
Train - Iteration 400: 	Loss_stepA: 0.1561
Train - Iteration 450: 	Loss_stepA: 0.1588
Train - Iteration 500: 	Loss_stepA: 0.1453
Train - Iteration 550: 	Loss_stepA: 0.1619
Train - Epoch [61]: 	Loss_stepA: 0.1532
Test - Epoch [61]: 	Accuracy_stepA: 93.07%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0029
Train - Iteration 50: 	Loss_stepA: 0.1542
Train - Iteration 100: 	Loss_stepA: 0.1599
Train - Iteration 150: 	Loss_stepA: 0.1406
Train - Iteration 200: 	Loss_stepA: 0.1408
Train - Iteration 250: 	Loss_stepA: 0.1366
Train - Iteration 300: 	Loss_stepA: 0.1489
Train - Iteration 350: 	Loss_stepA: 0.1554
Train - Iteration 400: 	Loss_stepA: 0.1593
Train - Iteration 450: 	Loss_stepA: 0.1565
Train - Iteration 500: 	Loss_stepA: 0.1635
Train - Iteration 550: 	Loss_stepA: 0.1601
Train - Epoch [62]: 	Loss_stepA: 0.1525
Test - Epoch [62]: 	Accuracy_stepA: 93.00%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0021
Train - Iteration 50: 	Loss_stepA: 0.1284
Train - Iteration 100: 	Loss_stepA: 0.1507
Train - Iteration 150: 	Loss_stepA: 0.1302
Train - Iteration 200: 	Loss_stepA: 0.1462
Train - Iteration 250: 	Loss_stepA: 0.1502
Train - Iteration 300: 	Loss_stepA: 0.1520
Train - Iteration 350: 	Loss_stepA: 0.1469
Train - Iteration 400: 	Loss_stepA: 0.1508
Train - Iteration 450: 	Loss_stepA: 0.1473
Train - Iteration 500: 	Loss_stepA: 0.1667
Train - Iteration 550: 	Loss_stepA: 0.1547
Train - Epoch [63]: 	Loss_stepA: 0.1478
Test - Epoch [63]: 	Accuracy_stepA: 93.09%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0037
Train - Iteration 50: 	Loss_stepA: 0.1346
Train - Iteration 100: 	Loss_stepA: 0.1503
Train - Iteration 150: 	Loss_stepA: 0.1523
Train - Iteration 200: 	Loss_stepA: 0.1407
Train - Iteration 250: 	Loss_stepA: 0.1435
Train - Iteration 300: 	Loss_stepA: 0.1494
Train - Iteration 350: 	Loss_stepA: 0.1463
Train - Iteration 400: 	Loss_stepA: 0.1458
Train - Iteration 450: 	Loss_stepA: 0.1580
Train - Iteration 500: 	Loss_stepA: 0.1567
Train - Iteration 550: 	Loss_stepA: 0.1459
Train - Epoch [64]: 	Loss_stepA: 0.1479
Test - Epoch [64]: 	Accuracy_stepA: 92.97%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1402
Train - Iteration 100: 	Loss_stepA: 0.1565
Train - Iteration 150: 	Loss_stepA: 0.1484
Train - Iteration 200: 	Loss_stepA: 0.1493
Train - Iteration 250: 	Loss_stepA: 0.1486
Train - Iteration 300: 	Loss_stepA: 0.1415
Train - Iteration 350: 	Loss_stepA: 0.1507
Train - Iteration 400: 	Loss_stepA: 0.1590
Train - Iteration 450: 	Loss_stepA: 0.1521
Train - Iteration 500: 	Loss_stepA: 0.1536
Train - Iteration 550: 	Loss_stepA: 0.1423
Train - Epoch [65]: 	Loss_stepA: 0.1490
Test - Epoch [65]: 	Accuracy_stepA: 93.04%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0039
Train - Iteration 50: 	Loss_stepA: 0.1311
Train - Iteration 100: 	Loss_stepA: 0.1274
Train - Iteration 150: 	Loss_stepA: 0.1449
Train - Iteration 200: 	Loss_stepA: 0.1523
Train - Iteration 250: 	Loss_stepA: 0.1429
Train - Iteration 300: 	Loss_stepA: 0.1444
Train - Iteration 350: 	Loss_stepA: 0.1352
Train - Iteration 400: 	Loss_stepA: 0.1597
Train - Iteration 450: 	Loss_stepA: 0.1484
Train - Iteration 500: 	Loss_stepA: 0.1587
Train - Iteration 550: 	Loss_stepA: 0.1419
Train - Epoch [66]: 	Loss_stepA: 0.1440
Test - Epoch [66]: 	Accuracy_stepA: 93.20%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0018
Train - Iteration 50: 	Loss_stepA: 0.1471
Train - Iteration 100: 	Loss_stepA: 0.1352
Train - Iteration 150: 	Loss_stepA: 0.1446
Train - Iteration 200: 	Loss_stepA: 0.1432
Train - Iteration 250: 	Loss_stepA: 0.1485
Train - Iteration 300: 	Loss_stepA: 0.1434
Train - Iteration 350: 	Loss_stepA: 0.1538
Train - Iteration 400: 	Loss_stepA: 0.1416
Train - Iteration 450: 	Loss_stepA: 0.1526
Train - Iteration 500: 	Loss_stepA: 0.1469
Train - Iteration 550: 	Loss_stepA: 0.1316
Train - Epoch [67]: 	Loss_stepA: 0.1448
Test - Epoch [67]: 	Accuracy_stepA: 93.14%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0033
Train - Iteration 50: 	Loss_stepA: 0.1388
Train - Iteration 100: 	Loss_stepA: 0.1292
Train - Iteration 150: 	Loss_stepA: 0.1414
Train - Iteration 200: 	Loss_stepA: 0.1346
Train - Iteration 250: 	Loss_stepA: 0.1435
Train - Iteration 300: 	Loss_stepA: 0.1312
Train - Iteration 350: 	Loss_stepA: 0.1558
Train - Iteration 400: 	Loss_stepA: 0.1401
Train - Iteration 450: 	Loss_stepA: 0.1399
Train - Iteration 500: 	Loss_stepA: 0.1505
Train - Iteration 550: 	Loss_stepA: 0.1376
Train - Epoch [68]: 	Loss_stepA: 0.1409
Test - Epoch [68]: 	Accuracy_stepA: 93.00%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0020
Train - Iteration 50: 	Loss_stepA: 0.1317
Train - Iteration 100: 	Loss_stepA: 0.1411
Train - Iteration 150: 	Loss_stepA: 0.1456
Train - Iteration 200: 	Loss_stepA: 0.1441
Train - Iteration 250: 	Loss_stepA: 0.1381
Train - Iteration 300: 	Loss_stepA: 0.1364
Train - Iteration 350: 	Loss_stepA: 0.1340
Train - Iteration 400: 	Loss_stepA: 0.1418
Train - Iteration 450: 	Loss_stepA: 0.1383
Train - Iteration 500: 	Loss_stepA: 0.1363
Train - Iteration 550: 	Loss_stepA: 0.1376
Train - Epoch [69]: 	Loss_stepA: 0.1389
Test - Epoch [69]: 	Accuracy_stepA: 93.06%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0018
Train - Iteration 50: 	Loss_stepA: 0.1392
Train - Iteration 100: 	Loss_stepA: 0.1322
Train - Iteration 150: 	Loss_stepA: 0.1325
Train - Iteration 200: 	Loss_stepA: 0.1300
Train - Iteration 250: 	Loss_stepA: 0.1456
Train - Iteration 300: 	Loss_stepA: 0.1388
Train - Iteration 350: 	Loss_stepA: 0.1384
Train - Iteration 400: 	Loss_stepA: 0.1419
Train - Iteration 450: 	Loss_stepA: 0.1478
Train - Iteration 500: 	Loss_stepA: 0.1401
Train - Iteration 550: 	Loss_stepA: 0.1332
Train - Epoch [70]: 	Loss_stepA: 0.1379
Test - Epoch [70]: 	Accuracy_stepA: 93.17%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1264
Train - Iteration 100: 	Loss_stepA: 0.1350
Train - Iteration 150: 	Loss_stepA: 0.1177
Train - Iteration 200: 	Loss_stepA: 0.1363
Train - Iteration 250: 	Loss_stepA: 0.1374
Train - Iteration 300: 	Loss_stepA: 0.1377
Train - Iteration 350: 	Loss_stepA: 0.1331
Train - Iteration 400: 	Loss_stepA: 0.1408
Train - Iteration 450: 	Loss_stepA: 0.1399
Train - Iteration 500: 	Loss_stepA: 0.1336
Train - Iteration 550: 	Loss_stepA: 0.1425
Train - Epoch [71]: 	Loss_stepA: 0.1350
Test - Epoch [71]: 	Accuracy_stepA: 93.15%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0019
Train - Iteration 50: 	Loss_stepA: 0.1373
Train - Iteration 100: 	Loss_stepA: 0.1179
Train - Iteration 150: 	Loss_stepA: 0.1290
Train - Iteration 200: 	Loss_stepA: 0.1390
Train - Iteration 250: 	Loss_stepA: 0.1332
Train - Iteration 300: 	Loss_stepA: 0.1441
Train - Iteration 350: 	Loss_stepA: 0.1383
Train - Iteration 400: 	Loss_stepA: 0.1497
Train - Iteration 450: 	Loss_stepA: 0.1366
Train - Iteration 500: 	Loss_stepA: 0.1362
Train - Iteration 550: 	Loss_stepA: 0.1352
Train - Epoch [72]: 	Loss_stepA: 0.1355
Test - Epoch [72]: 	Accuracy_stepA: 93.16%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0037
Train - Iteration 50: 	Loss_stepA: 0.1288
Train - Iteration 100: 	Loss_stepA: 0.1257
Train - Iteration 150: 	Loss_stepA: 0.1309
Train - Iteration 200: 	Loss_stepA: 0.1300
Train - Iteration 250: 	Loss_stepA: 0.1396
Train - Iteration 300: 	Loss_stepA: 0.1295
Train - Iteration 350: 	Loss_stepA: 0.1388
Train - Iteration 400: 	Loss_stepA: 0.1344
Train - Iteration 450: 	Loss_stepA: 0.1363
Train - Iteration 500: 	Loss_stepA: 0.1301
Train - Iteration 550: 	Loss_stepA: 0.1520
Train - Epoch [73]: 	Loss_stepA: 0.1342
Test - Epoch [73]: 	Accuracy_stepA: 93.27%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0024
Train - Iteration 50: 	Loss_stepA: 0.1339
Train - Iteration 100: 	Loss_stepA: 0.1191
Train - Iteration 150: 	Loss_stepA: 0.1394
Train - Iteration 200: 	Loss_stepA: 0.1390
Train - Iteration 250: 	Loss_stepA: 0.1409
Train - Iteration 300: 	Loss_stepA: 0.1207
Train - Iteration 350: 	Loss_stepA: 0.1365
Train - Iteration 400: 	Loss_stepA: 0.1285
Train - Iteration 450: 	Loss_stepA: 0.1261
Train - Iteration 500: 	Loss_stepA: 0.1358
Train - Iteration 550: 	Loss_stepA: 0.1244
Train - Epoch [74]: 	Loss_stepA: 0.1310
Test - Epoch [74]: 	Accuracy_stepA: 93.14%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0018
Train - Iteration 50: 	Loss_stepA: 0.1332
Train - Iteration 100: 	Loss_stepA: 0.1192
Train - Iteration 150: 	Loss_stepA: 0.1300
Train - Iteration 200: 	Loss_stepA: 0.1186
Train - Iteration 250: 	Loss_stepA: 0.1293
Train - Iteration 300: 	Loss_stepA: 0.1295
Train - Iteration 350: 	Loss_stepA: 0.1270
Train - Iteration 400: 	Loss_stepA: 0.1319
Train - Iteration 450: 	Loss_stepA: 0.1232
Train - Iteration 500: 	Loss_stepA: 0.1407
Train - Iteration 550: 	Loss_stepA: 0.1385
Train - Epoch [75]: 	Loss_stepA: 0.1291
Test - Epoch [75]: 	Accuracy_stepA: 93.19%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0026
Train - Iteration 50: 	Loss_stepA: 0.1216
Train - Iteration 100: 	Loss_stepA: 0.1329
Train - Iteration 150: 	Loss_stepA: 0.1175
Train - Iteration 200: 	Loss_stepA: 0.1182
Train - Iteration 250: 	Loss_stepA: 0.1292
Train - Iteration 300: 	Loss_stepA: 0.1323
Train - Iteration 350: 	Loss_stepA: 0.1379
Train - Iteration 400: 	Loss_stepA: 0.1314
Train - Iteration 450: 	Loss_stepA: 0.1272
Train - Iteration 500: 	Loss_stepA: 0.1242
Train - Iteration 550: 	Loss_stepA: 0.1308
Train - Epoch [76]: 	Loss_stepA: 0.1276
Test - Epoch [76]: 	Accuracy_stepA: 93.15%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0027
Train - Iteration 50: 	Loss_stepA: 0.1173
Train - Iteration 100: 	Loss_stepA: 0.1177
Train - Iteration 150: 	Loss_stepA: 0.1139
Train - Iteration 200: 	Loss_stepA: 0.1182
Train - Iteration 250: 	Loss_stepA: 0.1304
Train - Iteration 300: 	Loss_stepA: 0.1325
Train - Iteration 350: 	Loss_stepA: 0.1340
Train - Iteration 400: 	Loss_stepA: 0.1339
Train - Iteration 450: 	Loss_stepA: 0.1313
Train - Iteration 500: 	Loss_stepA: 0.1246
Train - Iteration 550: 	Loss_stepA: 0.1343
Train - Epoch [77]: 	Loss_stepA: 0.1262
Test - Epoch [77]: 	Accuracy_stepA: 93.14%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0036
Train - Iteration 50: 	Loss_stepA: 0.1238
Train - Iteration 100: 	Loss_stepA: 0.1175
Train - Iteration 150: 	Loss_stepA: 0.1311
Train - Iteration 200: 	Loss_stepA: 0.1353
Train - Iteration 250: 	Loss_stepA: 0.1231
Train - Iteration 300: 	Loss_stepA: 0.1149
Train - Iteration 350: 	Loss_stepA: 0.1262
Train - Iteration 400: 	Loss_stepA: 0.1306
Train - Iteration 450: 	Loss_stepA: 0.1332
Train - Iteration 500: 	Loss_stepA: 0.1290
Train - Iteration 550: 	Loss_stepA: 0.1244
Train - Epoch [78]: 	Loss_stepA: 0.1261
Test - Epoch [78]: 	Accuracy_stepA: 93.22%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0030
Train - Iteration 50: 	Loss_stepA: 0.1147
Train - Iteration 100: 	Loss_stepA: 0.1129
Train - Iteration 150: 	Loss_stepA: 0.1135
Train - Iteration 200: 	Loss_stepA: 0.1197
Train - Iteration 250: 	Loss_stepA: 0.1268
Train - Iteration 300: 	Loss_stepA: 0.1292
Train - Iteration 350: 	Loss_stepA: 0.1155
Train - Iteration 400: 	Loss_stepA: 0.1398
Train - Iteration 450: 	Loss_stepA: 0.1267
Train - Iteration 500: 	Loss_stepA: 0.1326
Train - Iteration 550: 	Loss_stepA: 0.1212
Train - Epoch [79]: 	Loss_stepA: 0.1238
Test - Epoch [79]: 	Accuracy_stepA: 93.30%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0035
Train - Iteration 50: 	Loss_stepA: 0.1269
Train - Iteration 100: 	Loss_stepA: 0.1225
Train - Iteration 150: 	Loss_stepA: 0.1223
Train - Iteration 200: 	Loss_stepA: 0.1214
Train - Iteration 250: 	Loss_stepA: 0.1213
Train - Iteration 300: 	Loss_stepA: 0.1147
Train - Iteration 350: 	Loss_stepA: 0.1226
Train - Iteration 400: 	Loss_stepA: 0.1215
Train - Iteration 450: 	Loss_stepA: 0.1305
Train - Iteration 500: 	Loss_stepA: 0.1215
Train - Iteration 550: 	Loss_stepA: 0.1238
Train - Epoch [80]: 	Loss_stepA: 0.1232
Test - Epoch [80]: 	Accuracy_stepA: 93.07%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0031
Train - Iteration 50: 	Loss_stepA: 0.1286
Train - Iteration 100: 	Loss_stepA: 0.1240
Train - Iteration 150: 	Loss_stepA: 0.1113
Train - Iteration 200: 	Loss_stepA: 0.1197
Train - Iteration 250: 	Loss_stepA: 0.1121
Train - Iteration 300: 	Loss_stepA: 0.1199
Train - Iteration 350: 	Loss_stepA: 0.1297
Train - Iteration 400: 	Loss_stepA: 0.1204
Train - Iteration 450: 	Loss_stepA: 0.1203
Train - Iteration 500: 	Loss_stepA: 0.1202
Train - Iteration 550: 	Loss_stepA: 0.1209
Train - Epoch [81]: 	Loss_stepA: 0.1209
Test - Epoch [81]: 	Accuracy_stepA: 93.06%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0033
Train - Iteration 50: 	Loss_stepA: 0.1131
Train - Iteration 100: 	Loss_stepA: 0.1230
Train - Iteration 150: 	Loss_stepA: 0.1220
Train - Iteration 200: 	Loss_stepA: 0.1168
Train - Iteration 250: 	Loss_stepA: 0.1090
Train - Iteration 300: 	Loss_stepA: 0.1104
Train - Iteration 350: 	Loss_stepA: 0.1151
Train - Iteration 400: 	Loss_stepA: 0.1225
Train - Iteration 450: 	Loss_stepA: 0.1266
Train - Iteration 500: 	Loss_stepA: 0.1213
Train - Iteration 550: 	Loss_stepA: 0.1263
Train - Epoch [82]: 	Loss_stepA: 0.1192
Test - Epoch [82]: 	Accuracy_stepA: 93.19%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0020
Train - Iteration 50: 	Loss_stepA: 0.1113
Train - Iteration 100: 	Loss_stepA: 0.1201
Train - Iteration 150: 	Loss_stepA: 0.1205
Train - Iteration 200: 	Loss_stepA: 0.1190
Train - Iteration 250: 	Loss_stepA: 0.1246
Train - Iteration 300: 	Loss_stepA: 0.1193
Train - Iteration 350: 	Loss_stepA: 0.1218
Train - Iteration 400: 	Loss_stepA: 0.1208
Train - Iteration 450: 	Loss_stepA: 0.1133
Train - Iteration 500: 	Loss_stepA: 0.1138
Train - Iteration 550: 	Loss_stepA: 0.1228
Train - Epoch [83]: 	Loss_stepA: 0.1184
Test - Epoch [83]: 	Accuracy_stepA: 93.15%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0017
Train - Iteration 50: 	Loss_stepA: 0.1017
Train - Iteration 100: 	Loss_stepA: 0.1184
Train - Iteration 150: 	Loss_stepA: 0.1177
Train - Iteration 200: 	Loss_stepA: 0.1168
Train - Iteration 250: 	Loss_stepA: 0.1236
Train - Iteration 300: 	Loss_stepA: 0.1138
Train - Iteration 350: 	Loss_stepA: 0.1130
Train - Iteration 400: 	Loss_stepA: 0.1239
Train - Iteration 450: 	Loss_stepA: 0.1180
Train - Iteration 500: 	Loss_stepA: 0.1156
Train - Iteration 550: 	Loss_stepA: 0.1219
Train - Epoch [84]: 	Loss_stepA: 0.1163
Test - Epoch [84]: 	Accuracy_stepA: 93.22%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1136
Train - Iteration 100: 	Loss_stepA: 0.1189
Train - Iteration 150: 	Loss_stepA: 0.1294
Train - Iteration 200: 	Loss_stepA: 0.1169
Train - Iteration 250: 	Loss_stepA: 0.1145
Train - Iteration 300: 	Loss_stepA: 0.1151
Train - Iteration 350: 	Loss_stepA: 0.1131
Train - Iteration 400: 	Loss_stepA: 0.1154
Train - Iteration 450: 	Loss_stepA: 0.1278
Train - Iteration 500: 	Loss_stepA: 0.1089
Train - Iteration 550: 	Loss_stepA: 0.1119
Train - Epoch [85]: 	Loss_stepA: 0.1173
Test - Epoch [85]: 	Accuracy_stepA: 93.20%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1081
Train - Iteration 100: 	Loss_stepA: 0.1081
Train - Iteration 150: 	Loss_stepA: 0.1145
Train - Iteration 200: 	Loss_stepA: 0.1135
Train - Iteration 250: 	Loss_stepA: 0.1229
Train - Iteration 300: 	Loss_stepA: 0.1181
Train - Iteration 350: 	Loss_stepA: 0.1148
Train - Iteration 400: 	Loss_stepA: 0.1122
Train - Iteration 450: 	Loss_stepA: 0.1167
Train - Iteration 500: 	Loss_stepA: 0.1196
Train - Iteration 550: 	Loss_stepA: 0.1106
Train - Epoch [86]: 	Loss_stepA: 0.1153
Test - Epoch [86]: 	Accuracy_stepA: 93.32%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0018
Train - Iteration 50: 	Loss_stepA: 0.1195
Train - Iteration 100: 	Loss_stepA: 0.1172
Train - Iteration 150: 	Loss_stepA: 0.0997
Train - Iteration 200: 	Loss_stepA: 0.1064
Train - Iteration 250: 	Loss_stepA: 0.0995
Train - Iteration 300: 	Loss_stepA: 0.1205
Train - Iteration 350: 	Loss_stepA: 0.1204
Train - Iteration 400: 	Loss_stepA: 0.1089
Train - Iteration 450: 	Loss_stepA: 0.1208
Train - Iteration 500: 	Loss_stepA: 0.1122
Train - Iteration 550: 	Loss_stepA: 0.1249
Train - Epoch [87]: 	Loss_stepA: 0.1132
Test - Epoch [87]: 	Accuracy_stepA: 93.34%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1062
Train - Iteration 100: 	Loss_stepA: 0.1139
Train - Iteration 150: 	Loss_stepA: 0.1134
Train - Iteration 200: 	Loss_stepA: 0.1084
Train - Iteration 250: 	Loss_stepA: 0.1090
Train - Iteration 300: 	Loss_stepA: 0.1030
Train - Iteration 350: 	Loss_stepA: 0.1246
Train - Iteration 400: 	Loss_stepA: 0.1122
Train - Iteration 450: 	Loss_stepA: 0.1226
Train - Iteration 500: 	Loss_stepA: 0.1105
Train - Iteration 550: 	Loss_stepA: 0.1065
Train - Epoch [88]: 	Loss_stepA: 0.1118
Test - Epoch [88]: 	Accuracy_stepA: 93.16%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0025
Train - Iteration 50: 	Loss_stepA: 0.1125
Train - Iteration 100: 	Loss_stepA: 0.1162
Train - Iteration 150: 	Loss_stepA: 0.1111
Train - Iteration 200: 	Loss_stepA: 0.1112
Train - Iteration 250: 	Loss_stepA: 0.1055
Train - Iteration 300: 	Loss_stepA: 0.0956
Train - Iteration 350: 	Loss_stepA: 0.1148
Train - Iteration 400: 	Loss_stepA: 0.1230
Train - Iteration 450: 	Loss_stepA: 0.1046
Train - Iteration 500: 	Loss_stepA: 0.1096
Train - Iteration 550: 	Loss_stepA: 0.1057
Train - Epoch [89]: 	Loss_stepA: 0.1104
Test - Epoch [89]: 	Accuracy_stepA: 93.19%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0011
Train - Iteration 50: 	Loss_stepA: 0.1062
Train - Iteration 100: 	Loss_stepA: 0.1136
Train - Iteration 150: 	Loss_stepA: 0.1089
Train - Iteration 200: 	Loss_stepA: 0.1093
Train - Iteration 250: 	Loss_stepA: 0.1019
Train - Iteration 300: 	Loss_stepA: 0.1066
Train - Iteration 350: 	Loss_stepA: 0.1219
Train - Iteration 400: 	Loss_stepA: 0.1197
Train - Iteration 450: 	Loss_stepA: 0.1106
Train - Iteration 500: 	Loss_stepA: 0.1228
Train - Iteration 550: 	Loss_stepA: 0.1073
Train - Epoch [90]: 	Loss_stepA: 0.1113
Test - Epoch [90]: 	Accuracy_stepA: 93.29%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0013
Train - Iteration 50: 	Loss_stepA: 0.0925
Train - Iteration 100: 	Loss_stepA: 0.0988
Train - Iteration 150: 	Loss_stepA: 0.1072
Train - Iteration 200: 	Loss_stepA: 0.1072
Train - Iteration 250: 	Loss_stepA: 0.0945
Train - Iteration 300: 	Loss_stepA: 0.1069
Train - Iteration 350: 	Loss_stepA: 0.1120
Train - Iteration 400: 	Loss_stepA: 0.1141
Train - Iteration 450: 	Loss_stepA: 0.1148
Train - Iteration 500: 	Loss_stepA: 0.1154
Train - Iteration 550: 	Loss_stepA: 0.1083
Train - Epoch [91]: 	Loss_stepA: 0.1073
Test - Epoch [91]: 	Accuracy_stepA: 93.24%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0014
Train - Iteration 50: 	Loss_stepA: 0.1102
Train - Iteration 100: 	Loss_stepA: 0.1033
Train - Iteration 150: 	Loss_stepA: 0.1076
Train - Iteration 200: 	Loss_stepA: 0.1111
Train - Iteration 250: 	Loss_stepA: 0.1090
Train - Iteration 300: 	Loss_stepA: 0.1096
Train - Iteration 350: 	Loss_stepA: 0.1007
Train - Iteration 400: 	Loss_stepA: 0.1084
Train - Iteration 450: 	Loss_stepA: 0.1021
Train - Iteration 500: 	Loss_stepA: 0.1032
Train - Iteration 550: 	Loss_stepA: 0.1130
Train - Epoch [92]: 	Loss_stepA: 0.1073
Test - Epoch [92]: 	Accuracy_stepA: 93.02%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0014
Train - Iteration 50: 	Loss_stepA: 0.1105
Train - Iteration 100: 	Loss_stepA: 0.1037
Train - Iteration 150: 	Loss_stepA: 0.1064
Train - Iteration 200: 	Loss_stepA: 0.1050
Train - Iteration 250: 	Loss_stepA: 0.1147
Train - Iteration 300: 	Loss_stepA: 0.1053
Train - Iteration 350: 	Loss_stepA: 0.1106
Train - Iteration 400: 	Loss_stepA: 0.1121
Train - Iteration 450: 	Loss_stepA: 0.1017
Train - Iteration 500: 	Loss_stepA: 0.1080
Train - Iteration 550: 	Loss_stepA: 0.1113
Train - Epoch [93]: 	Loss_stepA: 0.1083
Test - Epoch [93]: 	Accuracy_stepA: 93.25%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0016
Train - Iteration 50: 	Loss_stepA: 0.0935
Train - Iteration 100: 	Loss_stepA: 0.1015
Train - Iteration 150: 	Loss_stepA: 0.0995
Train - Iteration 200: 	Loss_stepA: 0.1007
Train - Iteration 250: 	Loss_stepA: 0.1002
Train - Iteration 300: 	Loss_stepA: 0.1071
Train - Iteration 350: 	Loss_stepA: 0.1033
Train - Iteration 400: 	Loss_stepA: 0.1100
Train - Iteration 450: 	Loss_stepA: 0.1208
Train - Iteration 500: 	Loss_stepA: 0.0999
Train - Iteration 550: 	Loss_stepA: 0.1115
Train - Epoch [94]: 	Loss_stepA: 0.1043
Test - Epoch [94]: 	Accuracy_stepA: 93.20%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0027
Train - Iteration 50: 	Loss_stepA: 0.0941
Train - Iteration 100: 	Loss_stepA: 0.1034
Train - Iteration 150: 	Loss_stepA: 0.1069
Train - Iteration 200: 	Loss_stepA: 0.0923
Train - Iteration 250: 	Loss_stepA: 0.1063
Train - Iteration 300: 	Loss_stepA: 0.1032
Train - Iteration 350: 	Loss_stepA: 0.1053
Train - Iteration 400: 	Loss_stepA: 0.1099
Train - Iteration 450: 	Loss_stepA: 0.1119
Train - Iteration 500: 	Loss_stepA: 0.1059
Train - Iteration 550: 	Loss_stepA: 0.1060
Train - Epoch [95]: 	Loss_stepA: 0.1039
Test - Epoch [95]: 	Accuracy_stepA: 93.19%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0019
Train - Iteration 50: 	Loss_stepA: 0.0925
Train - Iteration 100: 	Loss_stepA: 0.1037
Train - Iteration 150: 	Loss_stepA: 0.1068
Train - Iteration 200: 	Loss_stepA: 0.1089
Train - Iteration 250: 	Loss_stepA: 0.1115
Train - Iteration 300: 	Loss_stepA: 0.1082
Train - Iteration 350: 	Loss_stepA: 0.1010
Train - Iteration 400: 	Loss_stepA: 0.0967
Train - Iteration 450: 	Loss_stepA: 0.1049
Train - Iteration 500: 	Loss_stepA: 0.1111
Train - Iteration 550: 	Loss_stepA: 0.0949
Train - Epoch [96]: 	Loss_stepA: 0.1042
Test - Epoch [96]: 	Accuracy_stepA: 93.32%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0024
Train - Iteration 50: 	Loss_stepA: 0.0968
Train - Iteration 100: 	Loss_stepA: 0.0979
Train - Iteration 150: 	Loss_stepA: 0.0930
Train - Iteration 200: 	Loss_stepA: 0.1026
Train - Iteration 250: 	Loss_stepA: 0.1017
Train - Iteration 300: 	Loss_stepA: 0.1078
Train - Iteration 350: 	Loss_stepA: 0.1088
Train - Iteration 400: 	Loss_stepA: 0.1129
Train - Iteration 450: 	Loss_stepA: 0.1011
Train - Iteration 500: 	Loss_stepA: 0.1059
Train - Iteration 550: 	Loss_stepA: 0.0969
Train - Epoch [97]: 	Loss_stepA: 0.1023
Test - Epoch [97]: 	Accuracy_stepA: 93.27%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0021
Train - Iteration 50: 	Loss_stepA: 0.1005
Train - Iteration 100: 	Loss_stepA: 0.1060
Train - Iteration 150: 	Loss_stepA: 0.1018
Train - Iteration 200: 	Loss_stepA: 0.1012
Train - Iteration 250: 	Loss_stepA: 0.1009
Train - Iteration 300: 	Loss_stepA: 0.0971
Train - Iteration 350: 	Loss_stepA: 0.0997
Train - Iteration 400: 	Loss_stepA: 0.1121
Train - Iteration 450: 	Loss_stepA: 0.1063
Train - Iteration 500: 	Loss_stepA: 0.1076
Train - Iteration 550: 	Loss_stepA: 0.1050
Train - Epoch [98]: 	Loss_stepA: 0.1032
Test - Epoch [98]: 	Accuracy_stepA: 93.27%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0007
Train - Iteration 50: 	Loss_stepA: 0.0959
Train - Iteration 100: 	Loss_stepA: 0.0979
Train - Iteration 150: 	Loss_stepA: 0.1042
Train - Iteration 200: 	Loss_stepA: 0.1047
Train - Iteration 250: 	Loss_stepA: 0.1028
Train - Iteration 300: 	Loss_stepA: 0.0962
Train - Iteration 350: 	Loss_stepA: 0.0977
Train - Iteration 400: 	Loss_stepA: 0.0987
Train - Iteration 450: 	Loss_stepA: 0.1080
Train - Iteration 500: 	Loss_stepA: 0.1066
Train - Iteration 550: 	Loss_stepA: 0.0950
Train - Epoch [99]: 	Loss_stepA: 0.1005
Test - Epoch [99]: 	Accuracy_stepA: 93.17%
-----------------------------------------------------------------------------------------------

Train - Iteration 0: 	Loss_stepA: 0.0030
Train - Iteration 50: 	Loss_stepA: 0.0969
Train - Iteration 100: 	Loss_stepA: 0.0896
Train - Iteration 150: 	Loss_stepA: 0.0974
Train - Iteration 200: 	Loss_stepA: 0.0987
Train - Iteration 250: 	Loss_stepA: 0.0976
Train - Iteration 300: 	Loss_stepA: 0.0990
Train - Iteration 350: 	Loss_stepA: 0.1065
Train - Iteration 400: 	Loss_stepA: 0.0878
Train - Iteration 450: 	Loss_stepA: 0.0989
Train - Iteration 500: 	Loss_stepA: 0.1020
Train - Iteration 550: 	Loss_stepA: 0.0971
Train - Epoch [100]: 	Loss_stepA: 0.0973
Test - Epoch [100]: 	Accuracy_stepA: 93.16%
-----------------------------------------------------------------------------------------------

The process took 41.68030724525452 minutes to complete.
