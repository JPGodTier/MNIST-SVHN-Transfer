nohup: ignoring input
Using downloaded and verified file: ./data/SVHN/raw/train_32x32.mat
Using downloaded and verified file: ./data/SVHN/raw/test_32x32.mat
Using device cuda
Training starts
Epoch [1/10] starts
Iteration 50: Loss_G: 10.1359, Loss_D: 0.0390
Iteration 100: Loss_G: 5.9154, Loss_D: 0.0365
Iteration 150: Loss_G: 4.2956, Loss_D: 0.0594
Iteration 200: Loss_G: 3.9509, Loss_D: 0.0698
Iteration 250: Loss_G: 3.6805, Loss_D: 0.0768
Iteration 300: Loss_G: 3.3951, Loss_D: 0.0752
Iteration 350: Loss_G: 3.3423, Loss_D: 0.0772
Iteration 400: Loss_G: 3.2610, Loss_D: 0.0728
Iteration 450: Loss_G: 3.2493, Loss_D: 0.0729
Iteration 500: Loss_G: 3.2522, Loss_D: 0.0736
Iteration 550: Loss_G: 3.2703, Loss_D: 0.0719
Iteration 600: Loss_G: 3.2035, Loss_D: 0.0767
Iteration 650: Loss_G: 3.1830, Loss_D: 0.0652
Iteration 700: Loss_G: 2.9646, Loss_D: 0.0875
Iteration 750: Loss_G: 3.1389, Loss_D: 0.0706
Iteration 800: Loss_G: 3.0314, Loss_D: 0.0829
Iteration 850: Loss_G: 3.0028, Loss_D: 0.0752
Iteration 900: Loss_G: 3.0205, Loss_D: 0.0855
Iteration 950: Loss_G: 2.8493, Loss_D: 0.0877
Iteration 1000: Loss_G: 2.8855, Loss_D: 0.0895
Iteration 1050: Loss_G: 2.8273, Loss_D: 0.0859
Iteration 1100: Loss_G: 3.0393, Loss_D: 0.0787
Iteration 1150: Loss_G: 2.7770, Loss_D: 0.0872
Iteration 1200: Loss_G: 2.8676, Loss_D: 0.0787
Epoch [1/10], Loss_G: 2.9515, Loss_D: 0.0740
Epoch [2/10] starts
Iteration 50: Loss_G: 2.9290, Loss_D: 0.0916
Iteration 100: Loss_G: 2.7403, Loss_D: 0.0885
Iteration 150: Loss_G: 2.7936, Loss_D: 0.0870
Iteration 200: Loss_G: 2.8723, Loss_D: 0.0858
Iteration 250: Loss_G: 2.7335, Loss_D: 0.0909
Iteration 300: Loss_G: 2.8260, Loss_D: 0.0910
Iteration 350: Loss_G: 2.8687, Loss_D: 0.0909
Iteration 400: Loss_G: 2.8274, Loss_D: 0.0885
Iteration 450: Loss_G: 2.7636, Loss_D: 0.0943
Iteration 500: Loss_G: 2.7485, Loss_D: 0.0918
Iteration 550: Loss_G: 2.8389, Loss_D: 0.0950
Iteration 600: Loss_G: 2.7261, Loss_D: 0.0914
Iteration 650: Loss_G: 2.8042, Loss_D: 0.0923
Iteration 700: Loss_G: 2.8698, Loss_D: 0.0966
Iteration 750: Loss_G: 2.7094, Loss_D: 0.0973
Iteration 800: Loss_G: 2.7426, Loss_D: 0.0946
Iteration 850: Loss_G: 2.6628, Loss_D: 0.0986
Iteration 900: Loss_G: 2.6503, Loss_D: 0.0962
Iteration 950: Loss_G: 2.6565, Loss_D: 0.0997
Iteration 1000: Loss_G: 2.5967, Loss_D: 0.0982
Iteration 1050: Loss_G: 2.5740, Loss_D: 0.1004
Iteration 1100: Loss_G: 2.5309, Loss_D: 0.1024
Iteration 1150: Loss_G: 2.5566, Loss_D: 0.0987
Iteration 1200: Loss_G: 2.5645, Loss_D: 0.0992
Epoch [2/10], Loss_G: 2.2369, Loss_D: 0.0942
Epoch [3/10] starts
Iteration 50: Loss_G: 2.6104, Loss_D: 0.0990
Iteration 100: Loss_G: 2.5805, Loss_D: 0.1004
Iteration 150: Loss_G: 2.6855, Loss_D: 0.0994
Iteration 200: Loss_G: 2.5975, Loss_D: 0.1017
Iteration 250: Loss_G: 2.5921, Loss_D: 0.1008
Iteration 300: Loss_G: 2.6346, Loss_D: 0.1011
Iteration 350: Loss_G: 2.6046, Loss_D: 0.1040
Iteration 400: Loss_G: 2.4384, Loss_D: 0.0991
Iteration 450: Loss_G: 2.5633, Loss_D: 0.1052
Iteration 500: Loss_G: 2.5861, Loss_D: 0.1067
Iteration 550: Loss_G: 2.6414, Loss_D: 0.1045
Iteration 600: Loss_G: 2.5098, Loss_D: 0.1017
Iteration 650: Loss_G: 2.7429, Loss_D: 0.1025
Iteration 700: Loss_G: 2.5064, Loss_D: 0.1035
Iteration 750: Loss_G: 2.6673, Loss_D: 0.0983
Iteration 800: Loss_G: 2.6516, Loss_D: 0.1029
Iteration 850: Loss_G: 2.4550, Loss_D: 0.1081
Iteration 900: Loss_G: 2.5527, Loss_D: 0.1025
Iteration 950: Loss_G: 2.4661, Loss_D: 0.1087
Iteration 1000: Loss_G: 2.4587, Loss_D: 0.0990
Iteration 1050: Loss_G: 2.5925, Loss_D: 0.1042
Iteration 1100: Loss_G: 2.5137, Loss_D: 0.1065
Iteration 1150: Loss_G: 2.4127, Loss_D: 0.1034
Iteration 1200: Loss_G: 2.5856, Loss_D: 0.1034
Epoch [3/10], Loss_G: 2.1026, Loss_D: 0.1028
Epoch [4/10] starts
Iteration 50: Loss_G: 2.5485, Loss_D: 0.1052
Iteration 100: Loss_G: 2.5789, Loss_D: 0.1067
Iteration 150: Loss_G: 2.5355, Loss_D: 0.1028
Iteration 200: Loss_G: 2.5471, Loss_D: 0.1033
Iteration 250: Loss_G: 2.5120, Loss_D: 0.1053
Iteration 300: Loss_G: 2.5713, Loss_D: 0.1038
Iteration 350: Loss_G: 2.4682, Loss_D: 0.1037
Iteration 400: Loss_G: 2.4745, Loss_D: 0.1083
Iteration 450: Loss_G: 2.4517, Loss_D: 0.1073
Iteration 500: Loss_G: 2.3953, Loss_D: 0.1090
Iteration 550: Loss_G: 2.4924, Loss_D: 0.1036
Iteration 600: Loss_G: 2.5291, Loss_D: 0.1051
Iteration 650: Loss_G: 2.5846, Loss_D: 0.1046
Iteration 700: Loss_G: 2.5023, Loss_D: 0.1085
Iteration 750: Loss_G: 2.4771, Loss_D: 0.1051
Iteration 800: Loss_G: 2.4910, Loss_D: 0.1080
Iteration 850: Loss_G: 2.2976, Loss_D: 0.1044
Iteration 900: Loss_G: 2.4806, Loss_D: 0.1073
Iteration 950: Loss_G: 2.4557, Loss_D: 0.1064
Iteration 1000: Loss_G: 2.4951, Loss_D: 0.1052
Iteration 1050: Loss_G: 2.3858, Loss_D: 0.1084
Iteration 1100: Loss_G: 2.4170, Loss_D: 0.1036
Iteration 1150: Loss_G: 2.4569, Loss_D: 0.1080
Iteration 1200: Loss_G: 2.4513, Loss_D: 0.1079
Epoch [4/10], Loss_G: 2.0327, Loss_D: 0.1059
Epoch [5/10] starts
Iteration 50: Loss_G: 2.4324, Loss_D: 0.1068
Iteration 100: Loss_G: 2.4781, Loss_D: 0.1104
Iteration 150: Loss_G: 2.4780, Loss_D: 0.1113
Iteration 200: Loss_G: 2.4742, Loss_D: 0.1049
Iteration 250: Loss_G: 2.5373, Loss_D: 0.1099
Iteration 300: Loss_G: 2.4988, Loss_D: 0.1072
Iteration 350: Loss_G: 2.4398, Loss_D: 0.1093
Iteration 400: Loss_G: 2.3625, Loss_D: 0.1083
Iteration 450: Loss_G: 2.5024, Loss_D: 0.1084
Iteration 500: Loss_G: 2.4066, Loss_D: 0.1056
Iteration 550: Loss_G: 2.4893, Loss_D: 0.1111
Iteration 600: Loss_G: 2.3510, Loss_D: 0.1080
Iteration 650: Loss_G: 2.4089, Loss_D: 0.1078
Iteration 700: Loss_G: 2.5466, Loss_D: 0.1059
Iteration 750: Loss_G: 2.4000, Loss_D: 0.1063
Iteration 800: Loss_G: 2.3432, Loss_D: 0.1063
Iteration 850: Loss_G: 2.4249, Loss_D: 0.1073
Iteration 900: Loss_G: 2.3619, Loss_D: 0.1084
Iteration 950: Loss_G: 2.4710, Loss_D: 0.1046
Iteration 1000: Loss_G: 2.3870, Loss_D: 0.1073
Iteration 1050: Loss_G: 2.3544, Loss_D: 0.1044
Iteration 1100: Loss_G: 2.4988, Loss_D: 0.1085
Iteration 1150: Loss_G: 2.4312, Loss_D: 0.1101
Iteration 1200: Loss_G: 2.4821, Loss_D: 0.1094
Epoch [5/10], Loss_G: 1.9973, Loss_D: 0.1078
Epoch [6/10] starts
Iteration 50: Loss_G: 2.2853, Loss_D: 0.1065
Iteration 100: Loss_G: 2.3285, Loss_D: 0.1114
Iteration 150: Loss_G: 2.4796, Loss_D: 0.1048
Iteration 200: Loss_G: 2.2744, Loss_D: 0.1089
Iteration 250: Loss_G: 2.4485, Loss_D: 0.1076
Iteration 300: Loss_G: 2.4847, Loss_D: 0.1079
Iteration 350: Loss_G: 2.3231, Loss_D: 0.1099
Iteration 400: Loss_G: 2.2797, Loss_D: 0.1078
Iteration 450: Loss_G: 2.4046, Loss_D: 0.1090
Iteration 500: Loss_G: 2.4230, Loss_D: 0.1048
Iteration 550: Loss_G: 2.4130, Loss_D: 0.1086
Iteration 600: Loss_G: 2.3856, Loss_D: 0.1050
Iteration 650: Loss_G: 2.3968, Loss_D: 0.1085
Iteration 700: Loss_G: 2.2825, Loss_D: 0.1063
Iteration 750: Loss_G: 2.3781, Loss_D: 0.1047
Iteration 800: Loss_G: 2.5305, Loss_D: 0.1028
Iteration 850: Loss_G: 2.3424, Loss_D: 0.1053
Iteration 900: Loss_G: 2.3876, Loss_D: 0.1044
Iteration 950: Loss_G: 2.3881, Loss_D: 0.1057
Iteration 1000: Loss_G: 2.3377, Loss_D: 0.1039
Iteration 1050: Loss_G: 2.4953, Loss_D: 0.1026
Iteration 1100: Loss_G: 2.2950, Loss_D: 0.1074
Iteration 1150: Loss_G: 2.4497, Loss_D: 0.1036
Iteration 1200: Loss_G: 2.2426, Loss_D: 0.1093
Epoch [6/10], Loss_G: 1.9460, Loss_D: 0.1065
Epoch [7/10] starts
Iteration 50: Loss_G: 2.4780, Loss_D: 0.1050
Iteration 100: Loss_G: 2.3371, Loss_D: 0.1065
Iteration 150: Loss_G: 2.4106, Loss_D: 0.1059
Iteration 200: Loss_G: 2.3640, Loss_D: 0.1062
Iteration 250: Loss_G: 2.5055, Loss_D: 0.1039
Iteration 300: Loss_G: 2.3571, Loss_D: 0.1057
Iteration 350: Loss_G: 2.4136, Loss_D: 0.1106
Iteration 400: Loss_G: 2.3238, Loss_D: 0.1069
Iteration 450: Loss_G: 2.2963, Loss_D: 0.1044
Iteration 500: Loss_G: 2.3962, Loss_D: 0.1062
Iteration 550: Loss_G: 2.3538, Loss_D: 0.1060
Iteration 600: Loss_G: 2.2495, Loss_D: 0.1070
Iteration 650: Loss_G: 2.3231, Loss_D: 0.1025
Iteration 700: Loss_G: 2.4297, Loss_D: 0.1079
Iteration 750: Loss_G: 2.4858, Loss_D: 0.1043
Iteration 800: Loss_G: 2.3443, Loss_D: 0.1010
Iteration 850: Loss_G: 2.3748, Loss_D: 0.1110
Iteration 900: Loss_G: 2.3508, Loss_D: 0.1064
Iteration 950: Loss_G: 2.3584, Loss_D: 0.1076
Iteration 1000: Loss_G: 2.3599, Loss_D: 0.1058
Iteration 1050: Loss_G: 2.3086, Loss_D: 0.1010
Iteration 1100: Loss_G: 2.3410, Loss_D: 0.1045
Iteration 1150: Loss_G: 2.4250, Loss_D: 0.1057
Iteration 1200: Loss_G: 2.3649, Loss_D: 0.1058
Epoch [7/10], Loss_G: 1.9424, Loss_D: 0.1057
Epoch [8/10] starts
Iteration 50: Loss_G: 3.4110, Loss_D: 0.0596
Iteration 100: Loss_G: 2.7354, Loss_D: 0.0936
Iteration 150: Loss_G: 2.5179, Loss_D: 0.1012
Iteration 200: Loss_G: 2.4614, Loss_D: 0.0999
Iteration 250: Loss_G: 2.3452, Loss_D: 0.1006
Iteration 300: Loss_G: 2.4954, Loss_D: 0.1045
Iteration 350: Loss_G: 2.3569, Loss_D: 0.1037
Iteration 400: Loss_G: 2.3099, Loss_D: 0.1006
Iteration 450: Loss_G: 2.3525, Loss_D: 0.0988
Iteration 500: Loss_G: 2.3260, Loss_D: 0.1028
Iteration 550: Loss_G: 2.5075, Loss_D: 0.1014
Iteration 600: Loss_G: 2.4306, Loss_D: 0.1015
Iteration 650: Loss_G: 2.2889, Loss_D: 0.1049
Iteration 700: Loss_G: 2.4670, Loss_D: 0.0992
Iteration 750: Loss_G: 2.3695, Loss_D: 0.1015
Iteration 800: Loss_G: 2.5015, Loss_D: 0.0961
Iteration 850: Loss_G: 2.3603, Loss_D: 0.0997
Iteration 900: Loss_G: 2.3188, Loss_D: 0.0984
Iteration 950: Loss_G: 2.3258, Loss_D: 0.1034
Iteration 1000: Loss_G: 2.4902, Loss_D: 0.0963
Iteration 1050: Loss_G: 2.3499, Loss_D: 0.1019
Iteration 1100: Loss_G: 2.5190, Loss_D: 0.1002
Iteration 1150: Loss_G: 2.2930, Loss_D: 0.0966
Iteration 1200: Loss_G: 2.2364, Loss_D: 0.1015
Epoch [8/10], Loss_G: 2.0044, Loss_D: 0.0987
Epoch [9/10] starts
Iteration 50: Loss_G: 2.4801, Loss_D: 0.0931
Iteration 100: Loss_G: 2.3916, Loss_D: 0.1023
Iteration 150: Loss_G: 2.6707, Loss_D: 0.0961
Iteration 200: Loss_G: 2.9999, Loss_D: 0.0519
Iteration 250: Loss_G: 2.4983, Loss_D: 0.0960
Iteration 300: Loss_G: 2.4783, Loss_D: 0.0931
Iteration 350: Loss_G: 2.4187, Loss_D: 0.0964
Iteration 400: Loss_G: 2.4145, Loss_D: 0.1012
Iteration 450: Loss_G: 2.3880, Loss_D: 0.0954
Iteration 500: Loss_G: 2.4358, Loss_D: 0.0973
Iteration 550: Loss_G: 2.5938, Loss_D: 0.0910
Iteration 600: Loss_G: 2.3857, Loss_D: 0.1004
Iteration 650: Loss_G: 2.3065, Loss_D: 0.1008
Iteration 700: Loss_G: 2.2407, Loss_D: 0.0979
Iteration 750: Loss_G: 2.3332, Loss_D: 0.0990
Iteration 800: Loss_G: 2.3493, Loss_D: 0.0992
Iteration 850: Loss_G: 2.4078, Loss_D: 0.0961
Iteration 900: Loss_G: 2.4363, Loss_D: 0.1015
Iteration 950: Loss_G: 2.4074, Loss_D: 0.1004
Iteration 1000: Loss_G: 2.3143, Loss_D: 0.0996
Iteration 1050: Loss_G: 2.3971, Loss_D: 0.0960
Iteration 1100: Loss_G: 2.3046, Loss_D: 0.0980
Iteration 1150: Loss_G: 2.3047, Loss_D: 0.0990
Iteration 1200: Loss_G: 2.2478, Loss_D: 0.0988
Epoch [9/10], Loss_G: 1.9852, Loss_D: 0.0959
Epoch [10/10] starts
Iteration 50: Loss_G: 2.4135, Loss_D: 0.0944
Iteration 100: Loss_G: 2.3413, Loss_D: 0.0969
Iteration 150: Loss_G: 2.2629, Loss_D: 0.1018
Iteration 200: Loss_G: 2.1921, Loss_D: 0.1003
Iteration 250: Loss_G: 2.3926, Loss_D: 0.0975
Iteration 300: Loss_G: 2.2998, Loss_D: 0.0996
Iteration 350: Loss_G: 2.2753, Loss_D: 0.1029
Iteration 400: Loss_G: 2.2279, Loss_D: 0.0997
Iteration 450: Loss_G: 2.4327, Loss_D: 0.0927
Iteration 500: Loss_G: 2.4419, Loss_D: 0.0932
Iteration 550: Loss_G: 2.2002, Loss_D: 0.1011
Iteration 600: Loss_G: 2.2512, Loss_D: 0.0951
Iteration 650: Loss_G: 2.2936, Loss_D: 0.0996
Iteration 700: Loss_G: 2.2482, Loss_D: 0.1012
Iteration 750: Loss_G: 2.3904, Loss_D: 0.0923
Iteration 800: Loss_G: 2.3369, Loss_D: 0.1068
Iteration 850: Loss_G: 2.1907, Loss_D: 0.0968
Iteration 900: Loss_G: 2.2443, Loss_D: 0.0999
Iteration 950: Loss_G: 2.3163, Loss_D: 0.1020
Iteration 1000: Loss_G: 2.2909, Loss_D: 0.1001
Iteration 1050: Loss_G: 2.1894, Loss_D: 0.1055
Iteration 1100: Loss_G: 2.2222, Loss_D: 0.0977
Iteration 1150: Loss_G: 2.2086, Loss_D: 0.0977
Iteration 1200: Loss_G: 2.2333, Loss_D: 0.1020
Epoch [10/10], Loss_G: 1.8723, Loss_D: 0.0990
The process took 31.72952224810918 minutes to complete.
